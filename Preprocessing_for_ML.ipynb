{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing for ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cnbOzEZa3YST"
      ],
      "authorship_tag": "ABX9TyMRHKyGPxJpJY87tz7J7PpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferrariagustinpablo/Python-Machine-Learning-notebooks/blob/main/Preprocessing_for_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUVun9sj6E_U"
      },
      "source": [
        "Pre-processing comes after cleaning and exploratory data analysis (EDA) to understand you data set.\n",
        "\n",
        "This is preparing data for modeling.\n",
        "\n",
        "Models require only numerical imput.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5xWhANu2z_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_q47zpICn1E"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ua885fE6CY9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "0d26515f-0ad3-42f0-b54d-7738eff543bb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/668b96955d8b252aa8439c7602d516634e3f015e/volunteer_opportunities.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opportunity_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>vol_requests</th>\n",
              "      <th>event_time</th>\n",
              "      <th>title</th>\n",
              "      <th>hits</th>\n",
              "      <th>summary</th>\n",
              "      <th>is_priority</th>\n",
              "      <th>category_id</th>\n",
              "      <th>category_desc</th>\n",
              "      <th>amsl</th>\n",
              "      <th>amsl_unit</th>\n",
              "      <th>org_title</th>\n",
              "      <th>org_content_id</th>\n",
              "      <th>addresses_count</th>\n",
              "      <th>locality</th>\n",
              "      <th>region</th>\n",
              "      <th>postalcode</th>\n",
              "      <th>primary_loc</th>\n",
              "      <th>display_url</th>\n",
              "      <th>recurrence_type</th>\n",
              "      <th>hours</th>\n",
              "      <th>created_date</th>\n",
              "      <th>last_modified_date</th>\n",
              "      <th>start_date_date</th>\n",
              "      <th>end_date_date</th>\n",
              "      <th>status</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Community Board</th>\n",
              "      <th>Community Council</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>BIN</th>\n",
              "      <th>BBL</th>\n",
              "      <th>NTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4996</td>\n",
              "      <td>37004</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
              "      <td>737</td>\n",
              "      <td>Building on successful events last summer and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Center For NYC Neighborhoods</td>\n",
              "      <td>4426</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/4996</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 13 2011</td>\n",
              "      <td>June 23 2011</td>\n",
              "      <td>July 30 2011</td>\n",
              "      <td>July 30 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008</td>\n",
              "      <td>37036</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Web designer</td>\n",
              "      <td>22</td>\n",
              "      <td>Build a website for an Afghan business</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bpeace</td>\n",
              "      <td>37026</td>\n",
              "      <td>1</td>\n",
              "      <td>5 22nd St\\nNew York, NY 10010\\n(40.74053152272...</td>\n",
              "      <td>NY</td>\n",
              "      <td>10010.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5008</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 14 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5016</td>\n",
              "      <td>37143</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
              "      <td>62</td>\n",
              "      <td>Please join us and the students from Mott Hall...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Street Project</td>\n",
              "      <td>3001</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>10026.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5016</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 19 2011</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5022</td>\n",
              "      <td>37237</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>Fight global hunger and support women farmers ...</td>\n",
              "      <td>14</td>\n",
              "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oxfam America</td>\n",
              "      <td>2170</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>2114.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5022</td>\n",
              "      <td>ongoing</td>\n",
              "      <td>0</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 14 2011</td>\n",
              "      <td>March 31 2012</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5055</td>\n",
              "      <td>37425</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Stop 'N' Swap</td>\n",
              "      <td>31</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Office of Recycling Outreach and Education</td>\n",
              "      <td>36773</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>10455.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5055</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   opportunity_id  content_id  vol_requests  ...  BIN BBL  NTA\n",
              "0            4996       37004            50  ...  NaN NaN  NaN\n",
              "1            5008       37036             2  ...  NaN NaN  NaN\n",
              "2            5016       37143            20  ...  NaN NaN  NaN\n",
              "3            5022       37237           500  ...  NaN NaN  NaN\n",
              "4            5055       37425            15  ...  NaN NaN  NaN\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0jwITz97tk5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "2877e26e-3846-42d6-d34b-be8dc1b740c9"
      },
      "source": [
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(665, 35)\n",
            "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
            "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
            "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
            "       'locality', 'region', 'postalcode', 'primary_loc', 'display_url',\n",
            "       'recurrence_type', 'hours', 'created_date', 'last_modified_date',\n",
            "       'start_date_date', 'end_date_date', 'status', 'Latitude', 'Longitude',\n",
            "       'Community Board', 'Community Council ', 'Census Tract', 'BIN', 'BBL',\n",
            "       'NTA'],\n",
            "      dtype='object')\n",
            "opportunity_id          0\n",
            "content_id              0\n",
            "vol_requests            0\n",
            "event_time              0\n",
            "title                   0\n",
            "hits                    0\n",
            "summary                 0\n",
            "is_priority           603\n",
            "category_id            48\n",
            "category_desc          48\n",
            "amsl                  665\n",
            "amsl_unit             665\n",
            "org_title               0\n",
            "org_content_id          0\n",
            "addresses_count         0\n",
            "locality               70\n",
            "region                  0\n",
            "postalcode              6\n",
            "primary_loc           665\n",
            "display_url             0\n",
            "recurrence_type         0\n",
            "hours                   0\n",
            "created_date            0\n",
            "last_modified_date      0\n",
            "start_date_date         0\n",
            "end_date_date           0\n",
            "status                  0\n",
            "Latitude              665\n",
            "Longitude             665\n",
            "Community Board       665\n",
            "Community Council     665\n",
            "Census Tract          665\n",
            "BIN                   665\n",
            "BBL                   665\n",
            "NTA                   665\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LYX4bVW8sqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d860bfee-9225-4015-8087-766c74a49352"
      },
      "source": [
        "# Selecting rows where category_desc are all not null values.\n",
        "\n",
        "# Check how many values are missing in the category_desc column\n",
        "print(df[\"category_desc\"].isnull().sum())\n",
        "\n",
        "# Subset the volunteer dataset\n",
        "df = df[df[\"category_desc\"].notnull()]\n",
        "\n",
        "# Print out the shape of the subset\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(617, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AElJd1EF9GCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4f3a9496-820d-4931-aa8a-1b0aef1418ce"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "opportunity_id          int64\n",
              "content_id              int64\n",
              "vol_requests            int64\n",
              "event_time              int64\n",
              "title                  object\n",
              "hits                    int64\n",
              "summary                object\n",
              "category_id           float64\n",
              "category_desc          object\n",
              "org_title              object\n",
              "org_content_id          int64\n",
              "addresses_count         int64\n",
              "region                 object\n",
              "display_url            object\n",
              "recurrence_type        object\n",
              "hours                   int64\n",
              "created_date           object\n",
              "last_modified_date     object\n",
              "start_date_date        object\n",
              "end_date_date          object\n",
              "status                 object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6F2N4Aj_jJL"
      },
      "source": [
        "In the volunteer dataset, we're thinking about trying to predict the category_desc variable using the other features in the dataset. First, though, we need to know what the class distribution (and imbalance) is for that label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UshMygQEIBZ6"
      },
      "source": [
        "# Handling missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g4z6a2wD_2d"
      },
      "source": [
        "df.category_desc.dropna(axis=0,inplace=True)\n",
        "df.dropna(axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf8AzQuFIGp4"
      },
      "source": [
        "# Stratify in splitting if there is uneven labeling on target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtDci2xH-ugL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8b018c8f-2520-4c41-cdc5-84f2a4fcf81e"
      },
      "source": [
        "# The distribution is UNEVEN. \n",
        "# So if I train_test_split I should stratify the target dataset. In this case 'y'\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df.category_desc.value_counts()\n",
        "\n",
        "# Create a data with all columns except category_desc\n",
        "X = df.drop(\"category_desc\", axis=1)\n",
        "\n",
        "# Create a category_desc labels dataset\n",
        "y = df[[\"category_desc\"]]\n",
        "\n",
        "# Use stratified sampling to split up the dataset according to the y dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "# Print out the category_desc counts on the training y labels\n",
        "print(y_train[\"category_desc\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Strengthening Communities    230\n",
            "Helping Neighbors in Need     89\n",
            "Education                     69\n",
            "Health                        39\n",
            "Environment                   24\n",
            "Emergency Preparedness        11\n",
            "Name: category_desc, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5hrCQAwLAwP"
      },
      "source": [
        "# Standardize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqEYi_OzLExQ"
      },
      "source": [
        "When to standardize:\n",
        "\n",
        "Scikit-learn models assume normally distributed data\n",
        "\n",
        "Log normalization and feature scaling in this course\n",
        "\n",
        "Applied to continuous numerical data\n",
        "\n",
        "Space like KNN, linearRegression or K-Means clustering, the model is assuming that the data and features are related in a linear fashion.\n",
        "\n",
        "Standardize when features have high variance or features are in different scales.\n",
        "Standardization is a preprocessing task performed on numerical, continuous data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8X4Ndn5MkEh"
      },
      "source": [
        "## Log normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahik9m_WMmo6"
      },
      "source": [
        "Is a method for standardizing data can be useful when you have a particular column with high variance.\n",
        "\n",
        "Transforms values onto a scale that approximates normality. Capture relative changes in a linear model, when you still want to capture the magnitude of change and when you want to keep everything in the positive space.\n",
        "\n",
        "Log normalization from numpy np.log(df['col'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG5wxdsBIMWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "7866da1b-9b33-446c-9fc8-6b30bb68ab54"
      },
      "source": [
        "wine = pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/9bd5350dfdb481e0f94eeef6acf2663452a8ef8b/wine_types.csv')\n",
        "print(wine.shape)\n",
        "wine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(178, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Type  Alcohol  Malic acid  ...   Hue  OD280/OD315 of diluted wines  Proline\n",
              "0     1    14.23        1.71  ...  1.04                          3.92     1065\n",
              "1     1    13.20        1.78  ...  1.05                          3.40     1050\n",
              "2     1    13.16        2.36  ...  1.03                          3.17     1185\n",
              "3     1    14.37        1.95  ...  0.86                          3.45     1480\n",
              "4     1    13.24        2.59  ...  1.04                          2.93      735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELfGP9egOLwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "56572731-b507-4652-b58d-f3a097e5b262"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# See variances on each column of the dataset\n",
        "# feature Proline has excesively variance and/or different scales.\n",
        "display(wine.var())\n",
        "\n",
        "# We would need to apply Log normalization to that column.\n",
        "# Print out the variance of the Proline column\n",
        "print(wine[\"Proline\"].var())\n",
        "\n",
        "# Apply the log normalization function to the Proline column\n",
        "wine[\"Proline_log\"] = np.log(wine[\"Proline\"])\n",
        "\n",
        "# Check the variance of the normalized Proline column\n",
        "print(wine[\"Proline_log\"].var())\n",
        "display(wine.var())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Type                                0.600679\n",
              "Alcohol                             0.659062\n",
              "Malic acid                          1.248015\n",
              "Ash                                 0.075265\n",
              "Alcalinity of ash                  11.152686\n",
              "Magnesium                         203.989335\n",
              "Total phenols                       0.391690\n",
              "Flavanoids                          0.997719\n",
              "Nonflavanoid phenols                0.015489\n",
              "Proanthocyanins                     0.327595\n",
              "Color intensity                     5.374449\n",
              "Hue                                 0.052245\n",
              "OD280/OD315 of diluted wines        0.504086\n",
              "Proline                         99166.717355\n",
              "Proline_log                         0.172314\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "99166.71735542428\n",
            "0.17231366191842018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Type                                0.600679\n",
              "Alcohol                             0.659062\n",
              "Malic acid                          1.248015\n",
              "Ash                                 0.075265\n",
              "Alcalinity of ash                  11.152686\n",
              "Magnesium                         203.989335\n",
              "Total phenols                       0.391690\n",
              "Flavanoids                          0.997719\n",
              "Nonflavanoid phenols                0.015489\n",
              "Proanthocyanins                     0.327595\n",
              "Color intensity                     5.374449\n",
              "Hue                                 0.052245\n",
              "OD280/OD315 of diluted wines        0.504086\n",
              "Proline                         99166.717355\n",
              "Proline_log                         0.172314\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beD_QYqoPRSX"
      },
      "source": [
        "## Scaling data StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vp8wN1-PS09"
      },
      "source": [
        "Scaling is a method of Standardization that's most useful when you are working with a dataset that contains continuous features that are on different scales and you are using a model that operates in some sort of **linear space** (like linearRegression or KNN)\n",
        "\n",
        "Makes mean=0 variance=1 and transforms to approximately normal distribution. \n",
        "(to be normally distributed is a pre-requisite in scikit-learn)\n",
        "\n",
        "StandardScaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igd-bfOKQXDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49760838-39e1-4140-fc1b-36f38259f182"
      },
      "source": [
        "# Import StandardScaler from scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply the scaler to the DataFrame subset\n",
        "wine_scaled = scaler.fit_transform(wine)\n",
        "type(wine_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK4AML03Snsu"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crqE016zSp0p"
      },
      "source": [
        "What is feature engineering?\n",
        "\n",
        "Creation of new features based on existing features. \n",
        "\n",
        "Insight into relationships between features.\n",
        "\n",
        "Extract and expand data\n",
        "\n",
        "Text data, timestamps that can be broken into days or months.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnbOzEZa3YST"
      },
      "source": [
        "## Categorical variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiPDpgdo4U7u"
      },
      "source": [
        "### Binary columns with .apply"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eodL5Je73jIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "cf1e7694-ccc1-4a08-9139-223718358695"
      },
      "source": [
        "# For binary categorical columns, in example yes/no categorical variables\n",
        "\n",
        "# df['col'] = df['col'].apply(lambda x: 1 if val == 'y' else 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opportunity_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>vol_requests</th>\n",
              "      <th>event_time</th>\n",
              "      <th>title</th>\n",
              "      <th>hits</th>\n",
              "      <th>summary</th>\n",
              "      <th>category_id</th>\n",
              "      <th>category_desc</th>\n",
              "      <th>org_title</th>\n",
              "      <th>org_content_id</th>\n",
              "      <th>addresses_count</th>\n",
              "      <th>region</th>\n",
              "      <th>display_url</th>\n",
              "      <th>recurrence_type</th>\n",
              "      <th>hours</th>\n",
              "      <th>created_date</th>\n",
              "      <th>last_modified_date</th>\n",
              "      <th>start_date_date</th>\n",
              "      <th>end_date_date</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008</td>\n",
              "      <td>37036</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Web designer</td>\n",
              "      <td>22</td>\n",
              "      <td>Build a website for an Afghan business</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>Bpeace</td>\n",
              "      <td>37026</td>\n",
              "      <td>1</td>\n",
              "      <td>NY</td>\n",
              "      <td>/opportunities/5008</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 14 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5016</td>\n",
              "      <td>37143</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
              "      <td>62</td>\n",
              "      <td>Please join us and the students from Mott Hall...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>Street Project</td>\n",
              "      <td>3001</td>\n",
              "      <td>1</td>\n",
              "      <td>NY</td>\n",
              "      <td>/opportunities/5016</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 19 2011</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5022</td>\n",
              "      <td>37237</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>Fight global hunger and support women farmers ...</td>\n",
              "      <td>14</td>\n",
              "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>Oxfam America</td>\n",
              "      <td>2170</td>\n",
              "      <td>1</td>\n",
              "      <td>NY</td>\n",
              "      <td>/opportunities/5022</td>\n",
              "      <td>ongoing</td>\n",
              "      <td>0</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 14 2011</td>\n",
              "      <td>March 31 2012</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5055</td>\n",
              "      <td>37425</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Stop 'N' Swap</td>\n",
              "      <td>31</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>Office of Recycling Outreach and Education</td>\n",
              "      <td>36773</td>\n",
              "      <td>1</td>\n",
              "      <td>NY</td>\n",
              "      <td>/opportunities/5055</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5056</td>\n",
              "      <td>37426</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Queens Stop 'N' Swap</td>\n",
              "      <td>135</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>Office of Recycling Outreach and Education</td>\n",
              "      <td>36773</td>\n",
              "      <td>1</td>\n",
              "      <td>NY</td>\n",
              "      <td>/opportunities/5056</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>February 12 2011</td>\n",
              "      <td>February 12 2011</td>\n",
              "      <td>approved</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   opportunity_id  content_id  ...     end_date_date    status\n",
              "1            5008       37036  ...  February 01 2011  approved\n",
              "2            5016       37143  ...   January 29 2011  approved\n",
              "3            5022       37237  ...     March 31 2012  approved\n",
              "4            5055       37425  ...  February 05 2011  approved\n",
              "5            5056       37426  ...  February 12 2011  approved\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxAxsl474Xal"
      },
      "source": [
        "### Binary columns with LabelEncoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F7b3CJy4krX"
      },
      "source": [
        "# transforms y and n into 0 or 1s\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "df['col'] = le.fit_transform(df['col'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWacv_xr4xpf"
      },
      "source": [
        "### One-hot encoding (dummies)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfasBGx64-aX"
      },
      "source": [
        "pd.get_dummies(df['categorical_col'], drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ewpIZnm8w6D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqXwnaVv8y0F"
      },
      "source": [
        "## Engineering numerical features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgUYDqg883Sf"
      },
      "source": [
        "Aggregate statistics and dates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oge6GGyzA73I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "40e3e64c-cabf-4b82-f08d-9a16e01b9e19"
      },
      "source": [
        "# Example convert string into datetime and select only the month\n",
        "# You can also use attributes like .day to get the day and .year to get the year from datetime columns.\n",
        "\n",
        "# First, convert string column to date column\n",
        "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
        "\n",
        "# Extract just the month from the converted column\n",
        "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
        "\n",
        "# Take a look at the converted and new month columns\n",
        "print(volunteer[[\"start_date_converted\", \"start_date_month\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-b9118fc25126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First, convert string column to date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvolunteer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_date_converted\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolunteer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_date_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Extract just the month from the converted column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'volunteer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYbiLLvsBU0c"
      },
      "source": [
        "## Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQLYjMDqG3b_"
      },
      "source": [
        "### Regular Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJ2VjeLBbQO"
      },
      "source": [
        "Transform string into parts of string or other types of features\n",
        "\n",
        "How to extract data from strings: Regular Expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HewOyXitBw_u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00df8b08-1539-4db5-ed86-943566fba45c"
      },
      "source": [
        "# For example we have a string a we need to stract de float in it\n",
        "\n",
        "my_string = 'temperature:75.6 F'\n",
        "\n",
        "import re\n",
        "\n",
        "pattern = re.compile(r\"\\d+\\.\\d+\")\n",
        "\n",
        "temperature = re.search(pattern, my_string)\n",
        "\n",
        "# If a value is returned, use group(0) to return the found value\n",
        "print(temperature.group(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9zhXtO0DBLW"
      },
      "source": [
        "\\d means we want to grab **digits**.\n",
        "\n",
        "\\d+ means we want to grab as many as possible\n",
        "\n",
        "\n",
        "\\. mean we want to grab the decimal point\n",
        "\n",
        "and then there's another \\d+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtthXMK0TAh8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3b81bdc-37fd-4253-faa0-2bae1390fb25"
      },
      "source": [
        "my_string = 'temperature:75.6 F'\n",
        "\n",
        "import re\n",
        "\n",
        "re.findall(r\"\\d+\\.\\d+\", my_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['75.6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glZ9qhvwG5Uu"
      },
      "source": [
        "### Vectorizing TF-IDF Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xthoMWYMHYqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a1f89d6b-d51e-4c84-d29d-53c381f5b3ed"
      },
      "source": [
        "hiking = pd.read_json('https://assets.datacamp.com/production/repositories/1816/datasets/4f26c48451bdbf73db8a58e226cd3d6b45cf7bb5/hiking.json')\n",
        "hiking.head()\n",
        "\n",
        "hiking.Length.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.8 miles\n",
              "1      1.0 mile\n",
              "2    0.75 miles\n",
              "3     0.5 miles\n",
              "4     0.5 miles\n",
              "Name: Length, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb4WEUwlIwxH"
      },
      "source": [
        "# Write a pattern to extract numbers and decimals\n",
        "def return_mileage(length):\n",
        "    pattern = re.compile(\"\\d+\\.\\d+\")\n",
        "    \n",
        "    # Search the text for matches\n",
        "    mile = pattern.match(pattern, length)\n",
        "    \n",
        "    # If a value is returned, use group(0) to return the found value\n",
        "    if mile is not None:\n",
        "        return float(mile.group(0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU_xTTTLLKf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1e9fb401-a482-4669-d1fc-8f55e0e3b10f"
      },
      "source": [
        "# Apply the function to the Length column and take a look at both columns\n",
        "hiking[\"Length_num\"] = hiking[\"Length\"].apply(return_mileage)\n",
        "print(hiking[[\"Length\", \"Length_num\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-7f2a8c4e160a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply the function to the Length column and take a look at both columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhiking\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Length_num\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhiking\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_mileage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiking\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Length_num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-6146bd3d82fc>\u001b[0m in \u001b[0;36mreturn_mileage\u001b[0;34m(length)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Search the text for matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# If a value is returned, use group(0) to return the found value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39h5pS3KG811"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtbH8oJ2aqD-"
      },
      "source": [
        "after vectorize text we look at word weights\n",
        "\n",
        "tfidf_vec.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5cgAR5VVuvw"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Igyo4HV63x"
      },
      "source": [
        "Difference with feature engineering is that feature selection doesn't create new features.\n",
        "\n",
        "Improve model's performance.\n",
        "\n",
        "The objective is to remove redundant features, noisy features,correlated (remember that linear models assume feature independence) or duplicated features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DMQW5HlYTqm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMxWCd0dmnn-"
      },
      "source": [
        "# All pre-processing of UFO dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH3I6zxCVwWr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "c3514fba-b0af-43bd-8547-b8d77b7cfd1d"
      },
      "source": [
        "ufo = pd.read_csv('https://assets.datacamp.com/production/repositories/1816/datasets/a5ebfe5d2ed194f2668867603b563963af4769e9/ufo_sightings_large.csv')\n",
        "ufo.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>type</th>\n",
              "      <th>seconds</th>\n",
              "      <th>length_of_time</th>\n",
              "      <th>desc</th>\n",
              "      <th>recorded</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/3/2011 19:21</td>\n",
              "      <td>woodville</td>\n",
              "      <td>wi</td>\n",
              "      <td>us</td>\n",
              "      <td>unknown</td>\n",
              "      <td>1209600.0</td>\n",
              "      <td>2 weeks</td>\n",
              "      <td>Red blinking objects similar to airplanes or s...</td>\n",
              "      <td>12/12/2011</td>\n",
              "      <td>44.9530556</td>\n",
              "      <td>-92.291111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10/3/2004 19:05</td>\n",
              "      <td>cleveland</td>\n",
              "      <td>oh</td>\n",
              "      <td>us</td>\n",
              "      <td>circle</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30sec.</td>\n",
              "      <td>Many fighter jets flying towards UFO</td>\n",
              "      <td>10/27/2004</td>\n",
              "      <td>41.4994444</td>\n",
              "      <td>-81.695556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9/25/2009 21:00</td>\n",
              "      <td>coon rapids</td>\n",
              "      <td>mn</td>\n",
              "      <td>us</td>\n",
              "      <td>cigar</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
              "      <td>12/12/2009</td>\n",
              "      <td>45.1200000</td>\n",
              "      <td>-93.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/21/2002 05:45</td>\n",
              "      <td>clemmons</td>\n",
              "      <td>nc</td>\n",
              "      <td>us</td>\n",
              "      <td>triangle</td>\n",
              "      <td>300.0</td>\n",
              "      <td>about 5 minutes</td>\n",
              "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
              "      <td>12/23/2002</td>\n",
              "      <td>36.0213889</td>\n",
              "      <td>-80.382222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8/19/2010 12:55</td>\n",
              "      <td>calgary (canada)</td>\n",
              "      <td>ab</td>\n",
              "      <td>ca</td>\n",
              "      <td>oval</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>A white spinning disc in the shape of an oval.</td>\n",
              "      <td>8/24/2010</td>\n",
              "      <td>51.083333</td>\n",
              "      <td>-114.083333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               date              city state  ...    recorded         lat        long\n",
              "0   11/3/2011 19:21         woodville    wi  ...  12/12/2011  44.9530556  -92.291111\n",
              "1   10/3/2004 19:05         cleveland    oh  ...  10/27/2004  41.4994444  -81.695556\n",
              "2   9/25/2009 21:00       coon rapids    mn  ...  12/12/2009  45.1200000  -93.287500\n",
              "3  11/21/2002 05:45          clemmons    nc  ...  12/23/2002  36.0213889  -80.382222\n",
              "4   8/19/2010 12:55  calgary (canada)    ab  ...   8/24/2010   51.083333 -114.083333\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7eR99tpmr7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "cbdf47ce-0b33-4729-ca54-3cd4e6604076"
      },
      "source": [
        "# Check the column types\n",
        "print(ufo.dtypes)\n",
        "\n",
        "# Change the type of seconds to float\n",
        "ufo[\"seconds\"] = ufo[\"seconds\"].astype(float)\n",
        "\n",
        "# Change the date column to type datetime\n",
        "ufo[\"date\"] = pd.to_datetime(ufo[\"date\"])\n",
        "\n",
        "# Check the column types\n",
        "print(ufo[[\"seconds\", \"date\"]].dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date               object\n",
            "city               object\n",
            "state              object\n",
            "country            object\n",
            "type               object\n",
            "seconds           float64\n",
            "length_of_time     object\n",
            "desc               object\n",
            "recorded           object\n",
            "lat                object\n",
            "long              float64\n",
            "dtype: object\n",
            "seconds           float64\n",
            "date       datetime64[ns]\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s7o_JPWncnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "ba69b02b-90fb-4e2b-922d-642c04458cd9"
      },
      "source": [
        "# Check how many values are missing in the length_of_time, state, and type columns\n",
        "print(ufo.isnull().sum())\n",
        "\n",
        "# Keep only rows where length_of_time, state, and type are not null\n",
        "ufo_no_missing = ufo[ufo[\"length_of_time\"].notnull() & \n",
        "          ufo[\"state\"].notnull() & \n",
        "          ufo[\"type\"].notnull()]\n",
        "\n",
        "# Print out the shape of the new dataset\n",
        "print(ufo_no_missing.shape)\n",
        "print(ufo_no_missing.isnull().sum())\n",
        "\n",
        "#ufo_no_missing.drop('country', inplace=True,axis=1)\n",
        "print(ufo_no_missing.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date                0\n",
            "city                9\n",
            "state             419\n",
            "country           680\n",
            "type              159\n",
            "seconds             0\n",
            "length_of_time    143\n",
            "desc                3\n",
            "recorded            0\n",
            "lat                 0\n",
            "long                0\n",
            "dtype: int64\n",
            "(4283, 11)\n",
            "date                0\n",
            "city                0\n",
            "state               0\n",
            "country           392\n",
            "type                0\n",
            "seconds             0\n",
            "length_of_time      0\n",
            "desc                0\n",
            "recorded            0\n",
            "lat                 0\n",
            "long                0\n",
            "dtype: int64\n",
            "date                0\n",
            "city                0\n",
            "state               0\n",
            "country           392\n",
            "type                0\n",
            "seconds             0\n",
            "length_of_time      0\n",
            "desc                0\n",
            "recorded            0\n",
            "lat                 0\n",
            "long                0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2B76ZloorSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7c85d552-71e7-4bad-f923-74c317f60d04"
      },
      "source": [
        "def return_minutes(time_string):\n",
        "    \n",
        "    # We'll use \\d+ to grab digits and match it to the column values\n",
        "    pattern = re.compile(r\"\\d+\")\n",
        "        \n",
        "    # Use match on the pattern and column\n",
        "    num = re.match(pattern, str(time_string))\n",
        "    if num is not None:\n",
        "        return int(num.group(0))\n",
        "        \n",
        "\n",
        "# Apply the extraction to the length_of_time column\n",
        "ufo[\"minutes\"] = ufo[\"length_of_time\"].apply(return_minutes)\n",
        "\n",
        "# Take a look at the head of both of the columns\n",
        "print(ufo[[\"length_of_time\", \"minutes\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    length_of_time  minutes\n",
            "0          2 weeks      2.0\n",
            "1           30sec.     30.0\n",
            "2              NaN      NaN\n",
            "3  about 5 minutes      NaN\n",
            "4                2      2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d0dXZ5Eq95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9c1c4b43-1702-4327-8f7f-6729427d56b4"
      },
      "source": [
        "# Check the variance of the seconds and minutes columns\n",
        "print(ufo[[\"seconds\", \"minutes\"]].var())\n",
        "\n",
        "# Log normalize the seconds column\n",
        "ufo[\"seconds_log\"] = np.log(ufo[\"seconds\"])\n",
        "\n",
        "# Print out the variance of just the seconds_log column\n",
        "print(ufo[\"seconds_log\"].var())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seconds    3.156735e+10\n",
            "minutes    8.709933e+02\n",
            "dtype: float64\n",
            "nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpQMIltIrgqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "557004a2-9343-4a73-b340-3a00bdb4ff5e"
      },
      "source": [
        "# There are couple of columns in the UFO dataset that need to be encoded \n",
        "# before they can be modeled through scikit-learn. \n",
        "# You'll do that transformation here, using both binary and one-hot \n",
        "# encoding methods.\n",
        "\n",
        "# Use Pandas to encode us values as 1 and others as 0\n",
        "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda val: 1 if val == \"us\" else 0)\n",
        "\n",
        "# Print the number of unique type values\n",
        "print(len(ufo[\"type\"].unique()))\n",
        "\n",
        "# Create a one-hot encoded set of the type values\n",
        "type_set = pd.get_dummies(ufo[\"type\"])\n",
        "\n",
        "# Concatenate this set back to the ufo DataFrame\n",
        "ufo = pd.concat([ufo, type_set], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA-wR4jNzCSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7dcd465f-a0b6-4842-9f19-ebd963d686e2"
      },
      "source": [
        "# Look at the first 5 rows of the date column\n",
        "print(ufo[\"date\"].head())\n",
        "\n",
        "# Extract the month from the date column\n",
        "ufo[\"month\"] = ufo[\"date\"].dt.month\n",
        "\n",
        "# Extract the year from the date column\n",
        "ufo[\"year\"] = ufo[\"date\"].apply(lambda row: row.year)\n",
        "\n",
        "# Take a look at the head of all three columns\n",
        "print(ufo[[\"date\", \"month\", \"year\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0   2011-11-03 19:21:00\n",
            "1   2004-10-03 19:05:00\n",
            "2   2009-09-25 21:00:00\n",
            "3   2002-11-21 05:45:00\n",
            "4   2010-08-19 12:55:00\n",
            "Name: date, dtype: datetime64[ns]\n",
            "                 date  month  year\n",
            "0 2011-11-03 19:21:00     11  2011\n",
            "1 2004-10-03 19:05:00     10  2004\n",
            "2 2009-09-25 21:00:00      9  2009\n",
            "3 2002-11-21 05:45:00     11  2002\n",
            "4 2010-08-19 12:55:00      8  2010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jsndJ3ezmZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9cba0b24-8723-45b2-f824-7b5654e0ad9a"
      },
      "source": [
        "ufo[\"desc\"] = ufo[\"desc\"].fillna(' ')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Take a look at the head of the desc field\n",
        "print(ufo[\"desc\"].head())\n",
        "\n",
        "# Create the tfidf vectorizer object\n",
        "vec = TfidfVectorizer()\n",
        "\n",
        "# Use vec's fit_transform method on the desc field\n",
        "desc_tfidf = vec.fit_transform(ufo[\"desc\"])\n",
        "\n",
        "# Look at the number of columns this creates.\n",
        "print(desc_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Red blinking objects similar to airplanes or s...\n",
            "1                 Many fighter jets flying towards UFO\n",
            "2    Green&#44 red&#44 and blue pulses of light tha...\n",
            "3    It was a large&#44 triangular shaped flying ob...\n",
            "4       A white spinning disc in the shape of an oval.\n",
            "Name: desc, dtype: object\n",
            "(4935, 6433)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMAsQhJv1XLH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad0c91f0-5581-45cb-c460-1019ff70ecd7"
      },
      "source": [
        "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
        "print(ufo[[\"seconds\", \"seconds_log\", \"minutes\"]].corr())\n",
        "\n",
        "# Make a list of features to drop   \n",
        "to_drop = [\"city\", \"country\", \"date\", \"desc\", \"lat\", \"length_of_time\", \"long\", \"minutes\", \"recorded\", \"seconds\", \"state\"]\n",
        "\n",
        "# Drop those features\n",
        "ufo_dropped = ufo.drop(to_drop, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              seconds  seconds_log   minutes\n",
            "seconds      1.000000     0.164613 -0.008161\n",
            "seconds_log  0.164613     1.000000  0.110072\n",
            "minutes     -0.008161     0.110072  1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}