{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Validation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKYOTqZ4ivV2rw7xHmFeil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferrariagustinpablo/Python-Machine-Learning-notebooks/blob/main/Model_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmR2u24aue6g"
      },
      "source": [
        "# Model Validation on RandomForestRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhJsL3Uqh9ud"
      },
      "source": [
        "Model Validation\n",
        "\n",
        "It consists in ensuring the model performs as expected on onseen data.\n",
        "\n",
        "Testing model performance on hold-out datasets\n",
        "\n",
        "**Selecting the best model, parameters and accuracy metrics.**\n",
        "\n",
        "The objective is to end up with the best performing model, achieving the best accuracy on new data. We need the lowest testing error as possible.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANO3VgdZh69t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "fe3077c4-207f-4fc1-be99-1d2ab93c34fd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://assets.datacamp.com/production/repositories/3981/datasets/bdbcfeff5aff20449bad8a8f1e66ae0169b9a26d/candy-data.csv')\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>competitorname</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>fruity</th>\n",
              "      <th>caramel</th>\n",
              "      <th>peanutyalmondy</th>\n",
              "      <th>nougat</th>\n",
              "      <th>crispedricewafer</th>\n",
              "      <th>hard</th>\n",
              "      <th>bar</th>\n",
              "      <th>pluribus</th>\n",
              "      <th>sugarpercent</th>\n",
              "      <th>pricepercent</th>\n",
              "      <th>winpercent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100 Grand</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.860</td>\n",
              "      <td>66.971725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3 Musketeers</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.511</td>\n",
              "      <td>67.602936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One dime</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.116</td>\n",
              "      <td>32.261086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One quarter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.511</td>\n",
              "      <td>46.116505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Air Heads</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.511</td>\n",
              "      <td>52.341465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  competitorname  chocolate  fruity  ...  sugarpercent  pricepercent  winpercent\n",
              "0      100 Grand          1       0  ...         0.732         0.860   66.971725\n",
              "1   3 Musketeers          1       0  ...         0.604         0.511   67.602936\n",
              "2       One dime          0       0  ...         0.011         0.116   32.261086\n",
              "3    One quarter          0       0  ...         0.011         0.511   46.116505\n",
              "4      Air Heads          0       1  ...         0.906         0.511   52.341465\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59KHpu6gmn9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "14889189-efb1-4f6a-8116-5293a897d408"
      },
      "source": [
        "y = df.winpercent\n",
        "\n",
        "X = df.drop(['competitorname','winpercent'], axis= 1)\n",
        "\n",
        "print(y.head())\n",
        "print(X.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    66.971725\n",
            "1    67.602936\n",
            "2    32.261086\n",
            "3    46.116505\n",
            "4    52.341465\n",
            "Name: winpercent, dtype: float64\n",
            "   chocolate  fruity  caramel  ...  pluribus  sugarpercent  pricepercent\n",
            "0          1       0        1  ...         0         0.732         0.860\n",
            "1          1       0        0  ...         0         0.604         0.511\n",
            "2          0       0        0  ...         0         0.011         0.116\n",
            "3          0       0        0  ...         0         0.011         0.511\n",
            "4          0       1        0  ...         0         0.906         0.511\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_yVC7-7l1AQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcff35ec-988b-46af-edfa-771c6032c7af"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.40,random_state=42)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwloSGdbmKtZ"
      },
      "source": [
        "Model's tend to have higher accuracy on observations they have seen before. In the candy dataset, predicting the popularity of Skittles will likely have higher accuracy than predicting the popularity of Andes Mints; Skittles is in the dataset, and Andes Mints is not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSY8zrOF9zq9"
      },
      "source": [
        "## Random Forest Mean Absolute Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFI49j01nNcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc58ba74-903b-4970-a7f3-6530f72a0720"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=50)\n",
        "\n",
        "# The model is fit using X_train and y_train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Create vectors of predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# mae(y_true, y_pred)\n",
        "# Train/Test Errors\n",
        "train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
        "test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
        "\n",
        "# Print the accuracy for seen and unseen data\n",
        "print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
        "print(\"Model error on unseen data: {0:.2f}.\".format(test_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model error on seen data: 3.68.\n",
            "Model error on unseen data: 9.95.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gJkcUBzv8DG"
      },
      "source": [
        "## RandomForest feature importances\n",
        "\n",
        "The most import parameters that make a huge impact in the model: \n",
        "\n",
        "1- n_estimators = Number of trees in the forest\n",
        "\n",
        "2- max_depth = maximum depth of the trees (or how many time we can split the data)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pjgqXFowxxZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d4c241d-c237-4be0-e069-c6f386306ff2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=50,max_depth=6,random_state=1111)\n",
        "\n",
        "# you can update parameters after the model has been instantiated\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Print how important each column is to the model\n",
        "for i, item in enumerate(rf.feature_importances_):\n",
        "    # Use i and item to print out the feature importance of each column\n",
        "    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chocolate: 0.34\n",
            "fruity: 0.05\n",
            "caramel: 0.01\n",
            "peanutyalmondy: 0.07\n",
            "nougat: 0.02\n",
            "crispedricewafer: 0.01\n",
            "hard: 0.01\n",
            "bar: 0.07\n",
            "pluribus: 0.02\n",
            "sugarpercent: 0.17\n",
            "pricepercent: 0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5haqvwn2BJr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "732c9280-5da4-4770-c6e8-d9d6d28900dc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a pd.Series of features importances\n",
        "importances = pd.Series(data=rf.feature_importances_,\n",
        "                        index= X_train.columns)\n",
        "\n",
        "# Sort importances\n",
        "importances_sorted = importances.sort_values()\n",
        "\n",
        "# Draw a horizontal barplot of importances_sorted\n",
        "importances_sorted.plot(kind='barh', color='lightgreen')\n",
        "plt.title('Features Importances')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNguWp7F9sIq"
      },
      "source": [
        "# RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVQp0xGW96w2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "969fca0b-ab3b-486d-da54-a09e17715cea"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://assets.datacamp.com/production/repositories/3981/datasets/e6ee6604b9eed121a015a993bfb225ddf656cf81/tic-tac-toe.csv')\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(958, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top-Left</th>\n",
              "      <th>Top-Middle</th>\n",
              "      <th>Top-Right</th>\n",
              "      <th>Middle-Left</th>\n",
              "      <th>Middle-Middle</th>\n",
              "      <th>Middle-Right</th>\n",
              "      <th>Bottom-Left</th>\n",
              "      <th>Bottom-Middle</th>\n",
              "      <th>Bottom-Right</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Top-Left Top-Middle Top-Right  ... Bottom-Middle Bottom-Right     Class\n",
              "0        x          x         x  ...             o            o  positive\n",
              "1        x          x         x  ...             x            o  positive\n",
              "2        x          x         x  ...             o            x  positive\n",
              "3        x          x         x  ...             b            b  positive\n",
              "4        x          x         x  ...             o            b  positive\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRbe6teAAGKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e175e718-dfd6-447e-c7d4-a1ae07ed6a1b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df = df.replace('x',1).replace('o',0).replace('b',0)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top-Left</th>\n",
              "      <th>Top-Middle</th>\n",
              "      <th>Top-Right</th>\n",
              "      <th>Middle-Left</th>\n",
              "      <th>Middle-Middle</th>\n",
              "      <th>Middle-Right</th>\n",
              "      <th>Bottom-Left</th>\n",
              "      <th>Bottom-Middle</th>\n",
              "      <th>Bottom-Right</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Top-Left  Top-Middle  Top-Right  ...  Bottom-Middle  Bottom-Right     Class\n",
              "0         1           1          1  ...              0             0  positive\n",
              "1         1           1          1  ...              1             0  positive\n",
              "2         1           1          1  ...              0             1  positive\n",
              "3         1           1          1  ...              0             0  positive\n",
              "4         1           1          1  ...              0             0  positive\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN6OeIrcBiwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1882b5a6-6ec8-4205-fd7e-64fcba317763"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df.Class\n",
        "X = df.drop('Class',axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=42)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6)\n",
        "\n",
        "# Fit the rfc model. \n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create arrays of predictions\n",
        "classification_predictions = rfc.predict(X_test)\n",
        "probability_predictions = rfc.predict_proba(X_test)\n",
        "\n",
        "# Print out count of binary predictions\n",
        "print(pd.Series(classification_predictions).value_counts())\n",
        "\n",
        "# Print the first value from probability_predictions\n",
        "print('The first predicted probabilities are: {}'.format(probability_predictions[0]))\n",
        "\n",
        "rfc.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive    137\n",
            "negative     55\n",
            "dtype: int64\n",
            "The first predicted probabilities are: [0.45576679 0.54423321]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_3gSOeIEPGQ"
      },
      "source": [
        "# Training, validation, and testing datasets\n",
        "\n",
        "test data = unseen data = new data = holdout data\n",
        "\n",
        "universal ratio: 80/20\n",
        "\n",
        "90/10 if we have little data\n",
        "70/30 when the model is computationally expensive\n",
        "\n",
        "There could be another test dataset that is called validation set. After train_test_split X and y into train and testing, we split testing into validation and testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUJePLEOEhAo"
      },
      "source": [
        "# Double training and testing\n",
        "\n",
        "# Create temporary training and final testing datasets\n",
        "X_temp, X_test, y_temp, y_test  =\\\n",
        "    train_test_split(X, y, test_size=0.20, random_state=1111)\n",
        "\n",
        "# Create the final training and validation datasets\n",
        "X_train, X_val, y_train, y_val  =\\\n",
        "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwxuf_Q6HUSb"
      },
      "source": [
        "Why use holdout sets\n",
        "It is important to understand when you would use three datasets (training, validation, and testing) instead of two (training and testing). There is no point in creating an additional dataset split if you are not going to use it.\n",
        "\n",
        "When should you consider using training, validation, and testing datasets?\n",
        "\n",
        "**Anytime we are evaluating model performance repeatedly we need to create training, validation, and testing datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEUUZeJYH7yL"
      },
      "source": [
        "# Accuracy metrics for regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAVPBpbI3sj"
      },
      "source": [
        "The simples metric used when validating models for regression models\n",
        "\n",
        "Continuous predicted values.\n",
        "\n",
        "We can use:\n",
        "\n",
        "1- Mean Absolute error. The simplest. Treats all points equally. Communicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy.\n",
        "\n",
        "2- Mean Squared error. We square the difference term. **Most widely used regression metric**. Outliers (highest/lower values) have more impact on the model performance.  If you run any additional models, you will try to beat an MSE of the first calculation, which is the average squared error of using your first model. Although the MSE is not as interpretable as the MAE, it will help us select a model that has fewer 'large' errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNrOWS4ZTgPu"
      },
      "source": [
        "# Accuracy metrics for classification models\n",
        "\n",
        "In these models we are predicting what category an observation falls into.\n",
        "\n",
        "Many accuracy metric available:\n",
        "\n",
        "1- **Precision**\n",
        "\n",
        "2- **Recall (also called sensitivity)**\n",
        "\n",
        "3- **Accuracy**\n",
        "\n",
        "4- Specificity\n",
        "\n",
        "5- F1-Score and its variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE1HacoXT6xK"
      },
      "source": [
        "We calculate this metrics from the confusion matrix\n",
        "\n",
        "Specially if there is a binary outcome confusion matrix is one of the first things I should review.\n",
        "\n",
        "Binary outcome: confusion matrix is a 2x2 matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqixz3fQW-x2"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6zNAK14HOps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "064c96fb-c418-4f66-b577-3a6b75a9ad6a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create predictions\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create and print the confusion matrix\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "print(cm)\n",
        "\n",
        "# Print the true positives (actual 1s that were predicted 1s)\n",
        "print(\"The number of true positives is: {}\".format(cm[1, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 50  10]\n",
            " [  0 132]]\n",
            "The number of true positives is: 132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1xUm2uyXCND"
      },
      "source": [
        "## Accuracy \n",
        "\n",
        "Easiest metric to understand and represents the overall ability of your model to correctly predict the correct classification.\n",
        "\n",
        " (TNegatives + TPositives) / total number of observations = (e.g. 0.85)\n",
        "\n",
        " In our case:\n",
        "\n",
        " (57+125) / (57+125+10) = 0.9479"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d86YZcjAapcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9d43fd1-2be1-48ff-ede8-11dfebdac5ce"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "accuracy_score(y_test, classification_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5885416666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdzDoYNzYB02"
      },
      "source": [
        "## Precision\n",
        "\n",
        "When the predicted value is 1, what percentage your model predicted was really 1 and what percentage wasn't\n",
        "\n",
        "The number of true positives out of all predicted positive values.\n",
        "This value is representative when having classes that are uneven distributed, like Spam 1% not Spam 99%, if a model predicts only not spam Accuracy will be 99%, but precision will be 0%.\n",
        "\n",
        "TP / (TP+FP) \n",
        "\n",
        "In our case:\n",
        "\n",
        "125 / 135 = 0.926"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J4kqe7hafEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36a81c52-b42b-4572-a7da-f7034511d62a"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Create precision or recall score based on the metric you imported\n",
        "score = precision_score(y_test, test_predictions, pos_label=\"positive\")\n",
        "\n",
        "# Print the final result\n",
        "print(\"The precision value is {0:.2f}\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The precision value is 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBVoJguWZERq"
      },
      "source": [
        "## Recall\n",
        "\n",
        "When the actual value is 1, what percentage your model predicted 1.\n",
        "\n",
        "Recall is used when we can't afford to loose any positive values.\n",
        "\n",
        "TP = (TP+FN)\n",
        "\n",
        "In our case:\n",
        "\n",
        "125 / 125+0 = 1 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyK3ZqRUdE_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "929f2a2f-259d-4c2f-9072-01faabd11228"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Create precision or recall score based on the metric you imported\n",
        "score = recall_score(y_test, test_predictions, pos_label=\"positive\")\n",
        "\n",
        "# Print the final result\n",
        "print(\"The precision value is {0:.2f}\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The precision value is 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNI-NP8teuaQ"
      },
      "source": [
        "# The bias-variance tradeoff\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pokNJfXffn_6"
      },
      "source": [
        "## Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maMvBBq4e88w"
      },
      "source": [
        "Variance: If model has high variance it follows training data to closely. That is overfit the model. In this case we have low training error but high test error.\n",
        "\n",
        "Overfitting occur when the model starts to attach meaning to the noise in the training data.\n",
        "\n",
        "Overfitting is easy to identify because we have lower training error than testing error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL1xGTSJfpGl"
      },
      "source": [
        "## Bias\n",
        "\n",
        "This terms applies when the model fails to find the actual relationship between data and the response. High training error and high testing error. Occurs when models underfit.\n",
        "\n",
        "The model doesn't find the underlying pattern available in the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZakzC7ZPgSvB"
      },
      "source": [
        "## The bias-variance tradeoff\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_kCbdHfOIyu"
      },
      "source": [
        "# Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPc6h4pM0-x"
      },
      "source": [
        "If our models are not generalizing well or if we have limited data, we should be careful using a single training/validation split. You should cross-validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94cmEAIW-AqM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "43549dc2-24c7-4ee1-e33c-68b48807ad5c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://assets.datacamp.com/production/repositories/3981/datasets/bdbcfeff5aff20449bad8a8f1e66ae0169b9a26d/candy-data.csv')\n",
        "\n",
        "y = df.winpercent\n",
        "\n",
        "X = df.drop(['competitorname','winpercent'], axis= 1)\n",
        "\n",
        "print(y.head())\n",
        "print(X.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    66.971725\n",
            "1    67.602936\n",
            "2    32.261086\n",
            "3    46.116505\n",
            "4    52.341465\n",
            "Name: winpercent, dtype: float64\n",
            "   chocolate  fruity  caramel  ...  pluribus  sugarpercent  pricepercent\n",
            "0          1       0        1  ...         0         0.732         0.860\n",
            "1          1       0        0  ...         0         0.604         0.511\n",
            "2          0       0        0  ...         0         0.011         0.116\n",
            "3          0       0        0  ...         0         0.011         0.511\n",
            "4          0       1        0  ...         0         0.906         0.511\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzakP-Ao-VtL"
      },
      "source": [
        "# Instruction 1: Load the cross-validation method\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Instruction 2: Load the random forest regression model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instruction 3: Load the mean squared error method\n",
        "# Instruction 4: Load the function for creating a scorer\n",
        "from sklearn.metrics import mean_squared_error_error, make_scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUx4JZy8-mt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74f84578-bbf5-451c-a0c9-7eb46234ddd9"
      },
      "source": [
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "\n",
        "mse = make_scorer(mean_squared_error)\n",
        "\n",
        "# Set up cross_val_score\n",
        "cv = cross_val_score(estimator=rfc,\n",
        "                     X=X,\n",
        "                     y=y,\n",
        "                     cv=10,\n",
        "                     scoring=make_scorer(mean_squared_error))\n",
        "\n",
        "# Print the mean error\n",
        "print(cv.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155.55845080026586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIpmLCIo-9OS"
      },
      "source": [
        "# Leave one out cross-validation\n",
        "\n",
        "what is LOOCV? making n cross validation for n samples. So you leave one one sample per cross-validation.\n",
        "\n",
        "**When to use LOOCV?**\n",
        "\n",
        "When the amount of training is limited\n",
        "\n",
        "You want the absolute best error estimate for new data.\n",
        "\n",
        "**Be cautious when: **\n",
        "\n",
        "Computational resources are limited\n",
        "\n",
        "You have a lot of data.\n",
        "\n",
        "You have a lot of parameters to test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4_OlgC0A8v1"
      },
      "source": [
        "In this candy data set that we only have few observations, LOOCV is a good technique to implement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wepmRQjS__N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e55121b7-9d62-40ae-ec97-1eef61cd493d"
      },
      "source": [
        "n_samples = X.shape[0]\n",
        "\n",
        "rfr = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "\n",
        "mae = make_scorer(mean_absolute_error)\n",
        "\n",
        "# Set up cross_val_score\n",
        "scores = cross_val_score(estimator=rfc,\n",
        "                     X=X,\n",
        "                     y=y,\n",
        "                     cv=n_samples,\n",
        "                     scoring=mae)\n",
        "\n",
        "# Print the mean and standard deviation\n",
        "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
        "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean of the errors is: 9.362301251545098.\n",
            "The standard deviation of the errors is: 7.399032885517822.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIhhQsmXB_i_"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "Parameters are: Learned or estimated from the data, the result of fitting a model. Not manually set. e.g. in Linear Regression the coeficients and the intercepto of the model. \n",
        "\n",
        "Hyperparameters are set before training occurs. \n",
        "\n",
        "For tuning you first need to specify the hyperparameters to tune and then the range of each.\n",
        "\n",
        "if you write .get_params() method on a DecisionTree you'll get 16 hyperparameters. in practice only a handful of these will be tuned ar the same time.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo1iJN_MEbKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "026e5a87-ac73-4b8e-9924-7aea8143409a"
      },
      "source": [
        "# Review the parameters of rfr\n",
        "print(rfr.get_params())\n",
        "\n",
        "# Maximum Depth\n",
        "max_depth = [4, 8, 12]\n",
        "\n",
        "# Minimum samples for a split\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Max features \n",
        "max_features = [4, 6, 8, 10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 25, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPtkgf4iE3zx"
      },
      "source": [
        "# Combine model validation with tuning\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_fCptZzHahK"
      },
      "source": [
        "## GridSearchCV\n",
        "\n",
        "Tests every possible combination\n",
        "\n",
        "Every additional hyperparameter increase training time exponentially\n",
        "\n",
        "\n",
        "GridSearching only possible with limited hyperparameters and ranges.\n",
        "\n",
        "Two alternatives to GridSearching:\n",
        "\n",
        "1- Random Searching\n",
        "\n",
        "2- Bayesian Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUQEhYg4HOlJ"
      },
      "source": [
        "## RandomizedGridCV on RandomForestRegressor\n",
        "\n",
        "This method will randomly select hyperparameters for each model run based on the used-defined hyperparameter space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsHRgzNzIcwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "116447e9-4559-48af-acd7-428f49468c84"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=1111)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Finish the dictionary by adding the max_depth parameter\n",
        "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
        "              \"max_features\": [2, 4, 6, 8, 10],\n",
        "              \"min_samples_split\": [2, 4, 8, 16]}\n",
        "\n",
        "# Create a random forest regression model\n",
        "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
        "\n",
        "# Create a scorer to use (use the mean squared error)\n",
        "scorer = make_scorer(mean_squared_error)\n",
        "\n",
        "# Build a random search using param_dist, rfr, and scorer\n",
        "rs = RandomizedSearchCV(\n",
        "        estimator=rfr,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=20, # n_iter is the number of iterations\n",
        "        cv=5,\n",
        "        scoring=scorer)\n",
        "\n",
        "rs.fit(X_train,y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=10, n_jobs=None,\n",
              "                                                   oob_score=False,\n",
              "                                                   random_state=1111, verbose=0,\n",
              "                                                   warm_start=False),\n",
              "                   iid='deprecated', n_iter=20, n_jobs=None,\n",
              "                   param_distributions={'max_depth': [2, 4, 6, 8],\n",
              "                                        'max_features': [2, 4, 6, 8, 10],\n",
              "                                        'min_samples_split': [2, 4, 8, 16]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring=make_scorer(mean_squared_error), verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFbgC0APYfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "97f4d30b-e90e-482c-914b-944abba5fb77"
      },
      "source": [
        "# Print best parameters: these parameters do produce the best testing MSE.\n",
        "print(rs.best_params_)\n",
        "\n",
        "# Print the best testing MSE\n",
        "print(rs.best_score_)\n",
        "\n",
        "\n",
        "print(rs.best_estimator_.get_params())\n",
        "\n",
        "y_pred = rs.best_estimator_.predict(X_test)\n",
        "\n",
        "# Compute rmse_test\n",
        "mse_test = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print mse_test\n",
        "print('Test MSE of best model: {:.3f}'.format(mse_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_split': 16, 'max_features': 2, 'max_depth': 6}\n",
            "151.52443725259224\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 6, 'max_features': 2, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 16, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n",
            "Test MSE of best model: 111.892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT_TDeL6Rt-f"
      },
      "source": [
        "## RandomizedGridCV on RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gH-Nm7EViKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32f2e561-c595-4b1f-c578-89a4a265ebb7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('https://assets.datacamp.com/production/repositories/3981/datasets/e6ee6604b9eed121a015a993bfb225ddf656cf81/tic-tac-toe.csv')\n",
        "\n",
        "print(df.shape)\n",
        "\n",
        "df = df.replace('x',1).replace('o',0).replace('b',0)\n",
        "\n",
        "y = df.Class\n",
        "X = df.drop('Class',axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(958, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqe0bbi0Weh4"
      },
      "source": [
        "y = y.apply(lambda row: 1 if row == 'positive' else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3MSzEi9RtfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "236461d9-aa3b-4895-a255-4b0873b8aa57"
      },
      "source": [
        "# We create a RandomForestClassifier focusing on model precision.\n",
        "# That is: When the predicted value is 1, what percentage your model \n",
        "# predicted was really 1 and what percentage wasn't\n",
        "\n",
        "from sklearn.metrics import precision_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "param_dist = {'max_depth': range(2, 12, 2),\n",
        " 'min_samples_split': range(2, 12, 2),\n",
        " 'n_estimators': [10, 25, 50]}\n",
        "\n",
        "# Create a precision scorer\n",
        "precision = make_scorer(precision_score)\n",
        "\n",
        "# Finalize the random search\n",
        "rs = RandomizedSearchCV(\n",
        "  estimator=rfc, param_distributions=param_dist,\n",
        "  scoring = precision,\n",
        "  cv=5, n_iter=10, random_state=1111)\n",
        "\n",
        "rs.fit(X, y)\n",
        "\n",
        "# print the mean test scores:\n",
        "print('The precision metric for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
        "# print the best model score:\n",
        "print('The best precision metric for a single model was: {}'.format(rs.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The precision metric for each run was: [0.94572763 0.77015239 0.67565701 0.96302298 0.94719551 0.9709777\n",
            " 0.67927918 0.91235796 0.96056099 0.9765119 ].\n",
            "The best precision metric for a single model was: 0.9765118959516244\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}