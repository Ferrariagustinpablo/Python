{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQqwvH59389TBuDtQV9oLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferrariagustinpablo/Python-Machine-Learning-notebooks/blob/main/Intro_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Yo8H4gQw3F"
      },
      "source": [
        "# WHat is NLP\n",
        "\n",
        "Natural Language processing is a field of study focused on making sense of language using statistics and computers.\n",
        "\n",
        "NLP applications include: \n",
        "\n",
        "1- Topic identification \n",
        "\n",
        "2- Text classification\n",
        "\n",
        "3- Chatbots\n",
        "\n",
        "4- Translation\n",
        "\n",
        "5- and others\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X7YSxQyQrfJ"
      },
      "source": [
        "# Introduction to Regular Expression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQzo1Dm4QYqZ"
      },
      "source": [
        "RE are Strings with a special syntax with allows us to match patterns in others strings.\n",
        "\n",
        "Regular Expressions or Regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAGK5FS3QTH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4573dcda-2ee9-45ac-d7f0-690c618b83d5"
      },
      "source": [
        "import re\n",
        "\n",
        "match = re.match('abc','abcdef')\n",
        "match.group(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSrqS7zRTvhr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKObBqYeS_yp"
      },
      "source": [
        "## '\\w+' Match the first word it founds\n",
        "\n",
        "\n",
        "\\w we will fin only the first character. If we add the plus symbol the we will get a word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcRqWNQyTHIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e6a4e2-6f16-4a2a-a07a-f70fc60d94df"
      },
      "source": [
        "word_re = '\\w+'\n",
        "\n",
        "match = re.match(word_re,'Hi there!! DUdeeee.')\n",
        "match"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 2), match='Hi'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPDY60JwTY3Q"
      },
      "source": [
        "## \\d to match digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzkQyZfaTeRb"
      },
      "source": [
        "## \\s space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKsDvlVeTho7"
      },
      "source": [
        "## .* wildcard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzeHBOdTmwe"
      },
      "source": [
        "## +or* greedy match like 'aaaaaaaaaaaa'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qSLhZQ3T65Y"
      },
      "source": [
        "## \\S NOT space - Capital letters negates them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Po4sspiT_t-"
      },
      "source": [
        "## [a-z] lowercase group like 'sgsmf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlItDF2fUMAs"
      },
      "source": [
        "# split, findall, search and match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oY_p4CSVzK4"
      },
      "source": [
        "It's important to prefix your regex patterns with r to ensure that your patterns are interpreted in the way you want them to. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghiWN-COUJiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1675eb-d2cb-40b6-e9c2-1e95a06f858b"
      },
      "source": [
        "re.split ('\\s+', 'Split all words by spaces.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Split', 'all', 'words', 'by', 'spaces.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8KpRaQYVEL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3f2b54-fc50-463b-d9bd-1f4ba7352988"
      },
      "source": [
        "# In find all we will extract what I want in the regex pattern.\n",
        "#Let's find only words in a string.\n",
        "\n",
        "pattern = r\"\\w+\"\n",
        "\n",
        "re.findall(pattern, \"Let's write RegEx! Yes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Let', 's', 'write', 'RegEx', 'Yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ZOFzi_V-Bo"
      },
      "source": [
        "the syntax for the regex library is to always to pass the pattern first, and then the string second."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTTtzn75Zmq8"
      },
      "source": [
        "## Difference between search and match\n",
        "\n",
        "re.search() and re.match() are pretty essential.\n",
        "\n",
        "Match will try to match the pattern at the beginning of the string, however, search will go through the entire string to look for match options. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoxmcw4iXlUg"
      },
      "source": [
        "## Practice Regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tah1x1zDVs2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90118e37-a84b-4318-e27d-e354a742daf0"
      },
      "source": [
        "my_string = \"Let's write RegEx! tHis Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\"\n",
        "\n",
        "# Write a pattern to match sentence endings: sentence_endings\n",
        "sentence_endings = r\"[.?!]\"\n",
        "# Split my_string on sentence endings and print the result\n",
        "print(re.split(sentence_endings, my_string))\n",
        "\n",
        "# Find all capitalized words in my_string and print the result\n",
        "capitalized_words = r\"[A-Z]\\w+\"\n",
        "print(re.findall(capitalized_words, my_string))\n",
        "\n",
        "# Split my_string on spaces and print the result\n",
        "spaces = r\"\\s+\"\n",
        "print(re.split(spaces, my_string))\n",
        "\n",
        "# Find all digits in my_string and print the result\n",
        "digits = r\"\\d+\"\n",
        "print(re.findall(digits, my_string))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Let's write RegEx\", \" tHis Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n",
            "['Let', 'RegEx', 'His', 'Won', 'Can', 'Or']\n",
            "[\"Let's\", 'write', 'RegEx!', 'tHis', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n",
            "['4', '19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxKpo23AXnje"
      },
      "source": [
        "# Introduction to tokenization\n",
        "\n",
        "What is tokenization?\n",
        "\n",
        "Tuning a string or documenta into tokens (smaller chunks)\n",
        "\n",
        "One of the first steps in preparing a text for NLP\n",
        "\n",
        "There are many different theories and rules\n",
        "\n",
        "One library to use on natural language toolkit is **nltk**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFXSRiaIj90Y"
      },
      "source": [
        "Tokenization is fundamental to NLP, and you'll end up using it a lot in text mining and information retrieval projects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXsRNBaoY_lb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4667447c-f009-4ded-8d6a-149575f5ebc1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URh_D63yYJ8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b3783-68a7-4346-8aac-5fe46cc92f34"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(\"Plenty more where that came from! Seriously, I carry a lot of ammo.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Plenty',\n",
              " 'more',\n",
              " 'where',\n",
              " 'that',\n",
              " 'came',\n",
              " 'from',\n",
              " '!',\n",
              " 'Seriously',\n",
              " ',',\n",
              " 'I',\n",
              " 'carry',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'ammo',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHPzjfU1ZHBx"
      },
      "source": [
        "We see that punctuation are individual token as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kID30eklrx3"
      },
      "source": [
        "## sent_tokenize and word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBIzhkcAaTVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7bb4b2-0cc5-4f52-e043-3bdf8fd3f5c6"
      },
      "source": [
        "scene_one = \"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\"\n",
        "\n",
        "# Import necessary modules\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Split scene_one into sentences: sentences\n",
        "sentences = sent_tokenize(scene_one)\n",
        "print(sentences)\n",
        "\n",
        "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
        "tokenized_sent = word_tokenize(sentences[3])\n",
        "print(tokenized_sent)\n",
        "\n",
        "# Make a set of unique tokens in the the fourth sentence\n",
        "unique_tokens = set(word_tokenize(scene_one))\n",
        "\n",
        "# Print the unique tokens result\n",
        "print(unique_tokens)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!', '[clop clop clop] \\nSOLDIER #1: Halt!', 'Who goes there?', 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.', 'King of the Britons, defeator of the Saxons, sovereign of all England!', 'SOLDIER #1: Pull the other one!', 'ARTHUR: I am, ...  and this is my trusty servant Patsy.', 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.', 'I must speak with your lord and master.', 'SOLDIER #1: What?', 'Ridden on a horse?', 'ARTHUR: Yes!', \"SOLDIER #1: You're using coconuts!\", 'ARTHUR: What?', \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\", 'ARTHUR: So?', \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\", 'ARTHUR: We found them.', 'SOLDIER #1: Found them?', 'In Mercea?', \"The coconut's tropical!\", 'ARTHUR: What do you mean?', 'SOLDIER #1: Well, this is a temperate zone.', 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?', 'SOLDIER #1: Are you suggesting coconuts migrate?', 'ARTHUR: Not at all.', 'They could be carried.', 'SOLDIER #1: What?', 'A swallow carrying a coconut?', 'ARTHUR: It could grip it by the husk!', \"SOLDIER #1: It's not a question of where he grips it!\", \"It's a simple question of weight ratios!\", 'A five ounce bird could not carry a one pound coconut.', \"ARTHUR: Well, it doesn't matter.\", 'Will you go and tell your master that Arthur from the Court of Camelot is here.', 'SOLDIER #1: Listen.', 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?', 'ARTHUR: Please!', 'SOLDIER #1: Am I right?', \"ARTHUR: I'm not interested!\", 'SOLDIER #2: It could be carried by an African swallow!', 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.', \"That's my point.\", 'SOLDIER #2: Oh, yeah, I agree with that.', 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!', 'SOLDIER #1: But then of course a-- African swallows are non-migratory.', 'SOLDIER #2: Oh, yeah...', \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!\", 'Supposing two swallows carried it together?', \"SOLDIER #1: No, they'd have to have it on a line.\", 'SOLDIER #2: Well, simple!', \"They'd just use a strand of creeper!\", 'SOLDIER #1: What, held under the dorsal guiding feathers?', 'SOLDIER #2: Well, why not?']\n",
            "['ARTHUR', ':', 'It', 'is', 'I', ',', 'Arthur', ',', 'son', 'of', 'Uther', 'Pendragon', ',', 'from', 'the', 'castle', 'of', 'Camelot', '.']\n",
            "{'No', 'It', '!', 'ridden', 'house', 'son', 'sovereign', 'Where', 'your', 'grips', 'right', 'sun', 'dorsal', \"'\", \"'s\", 'suggesting', 'They', 'coconut', 'fly', 'creeper', 'Britons', \"n't\", 'Pendragon', 'halves', 'there', \"'em\", 'grip', 'order', '--', 'will', 'if', 'forty-three', 'But', 'I', 'land', 'at', 'air-speed', 'every', '1', 'back', 'Camelot', 'they', 'climes', 'What', 'found', 'defeator', 'goes', 'bird', 'Mercea', 'carried', 'but', \"'d\", 'ounce', 'question', 'Arthur', 'carrying', 'Whoa', 'with', 'breadth', 'does', 'use', 'lord', 'two', 'may', 'held', 'swallow', 'by', 'KING', 'In', 'beat', 'to', 'interested', 'speak', 'wind', '?', 'ask', 'wants', 'Court', '.', 'England', 'using', 'since', 'do', 'weight', 'Wait', 'from', 'second', 'have', 'martin', 'he', 'one', 'SOLDIER', 'swallows', \"'re\", 'under', 'our', 'yeah', 'could', '2', 'just', 'together', 'seek', 'court', 'is', 'be', 'them', 'tropical', 'knights', '#', 'Found', 'warmer', 'Oh', 'We', 'That', 'on', 'of', 'other', 'strand', 'feathers', 'needs', 'times', 'a', 'horse', 'these', 'got', \"'ve\", 'Uther', 'anyway', 'me', 'through', '...', 'You', 'A', 'ratios', 'maintain', ',', 'trusty', 'plover', 'Am', 'Not', 'carry', 'coconuts', 'must', 'not', 'it', \"'m\", 'in', '[', 'then', 'castle', 'or', 'husk', 'mean', 'non-migratory', 'temperate', ':', 'length', 'guiding', 'Who', 'Will', 'am', 'that', 'strangers', 'velocity', 'kingdom', 'agree', 'five', 'Ridden', 'its', 'Saxons', 'Yes', 'King', 'African', 'go', 'an', 'maybe', 'empty', ']', 'Please', 'bangin', 'course', 'this', 'my', 'servant', 'winter', 'covered', 'SCENE', 'Are', 'simple', 'zone', 'bring', 'Well', 'The', 'tell', 'line', 'clop', 'So', 'minute', 'and', 'join', 'here', 'you', 'matter', 'why', 'where', 'Listen', 'migrate', 'pound', 'Pull', 'south', 'are', 'the', 'Halt', 'all', 'search', 'master', 'Supposing', 'wings', 'get', 'point', 'who', 'yet', 'ARTHUR', 'snows', 'European', 'Patsy'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzRy7JvFlv6q"
      },
      "source": [
        "## search and match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS9e7HfNkVmG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e602f80-5527-49d1-b3fe-69a4937f4ba4"
      },
      "source": [
        "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
        "match = re.search(\"coconuts\", scene_one)\n",
        "\n",
        "# Print the start and end indexes of match\n",
        "print(match.start(), match.end())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "580 588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xP9T8phnWFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02d73b18-5edb-44cb-b10b-65235fd57035"
      },
      "source": [
        "# Write a regular expression to search for anything in square brackets: pattern1\n",
        "pattern1 = r\"\\[.*\\]\"\n",
        "\n",
        "# Use re.search to find the first text in square brackets\n",
        "print(re.search(pattern1, scene_one))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_sre.SRE_Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s363oZxhohQy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc264ac4-23f2-47f2-dd97-2b50995ad539"
      },
      "source": [
        "# Find the script notation at the beginning of the fourth sentence\n",
        "# and print it, include the colon (:)\n",
        "pattern2 = r\"[\\w\\s]+:\"\n",
        "print(re.match(pattern2, sentences[3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_sre.SRE_Match object; span=(0, 6), match='ARTHUR'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdONIWV_pjYz"
      },
      "source": [
        "# Advanced tokenization with NLTK and regex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2urE6qNppG_"
      },
      "source": [
        "# Regex\n",
        "\n",
        "OR is represented using |\n",
        "You can define a group using ()\n",
        "You can define explicit character ranges using []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT-Nsj5np_J0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9768c8-c7bf-410e-d9c1-2eb744507a0d"
      },
      "source": [
        "import re\n",
        "\n",
        "match_digits_and_words = '(\\d+|\\w+)'\n",
        "\n",
        "re.findall(match_digits_and_words, 'He has 11 cats.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He', 'has', '11', 'cats']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f_vrtHhs74V"
      },
      "source": [
        "### [A-Za-z]+ upper and lowercase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6WtozQptDnk"
      },
      "source": [
        "### [0-9] only numbers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mayPN52etHY5"
      },
      "source": [
        "### [A-Za-z\\-\\.] upper lower, - and ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-uSRi_EtUmh"
      },
      "source": [
        "## (a-z) explicit a - and z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwWOow05tdGE"
      },
      "source": [
        "## (\\s+|,) spaces or a comma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFPvPvB9uzLs"
      },
      "source": [
        "### lowercase spaces and nums but not commas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LfqKjcstuJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17a4169-91d0-4df6-cfb4-871247113f6e"
      },
      "source": [
        "import re\n",
        "\n",
        "my_str = 'match lowercase spaces nums like 12, but no commas'\n",
        "\n",
        "re.match('[a-z0-9 ]+', my_str)\n",
        "\n",
        "# Once it hits a comma it can't match anymore"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 35), match='match lowercase spaces nums like 12'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVwyOTsnu2x8"
      },
      "source": [
        "### regexp_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC3Ol6K0u3WF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c93bc8-f593-4486-f0e8-17347ec8d0a6"
      },
      "source": [
        "# you want to retain sentence punctuation as separate tokens, \n",
        "# but have '#1' remain a single token.\n",
        "\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
        "\n",
        "pattern = (r\"(\\w+|#\\d|\\?|!)\")\n",
        "\n",
        "regexp_tokenize(my_string, pattern)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SOLDIER',\n",
              " '#1',\n",
              " 'Found',\n",
              " 'them',\n",
              " '?',\n",
              " 'In',\n",
              " 'Mercea',\n",
              " '?',\n",
              " 'The',\n",
              " 'coconut',\n",
              " 's',\n",
              " 'tropical',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvivSYdXxS1c"
      },
      "source": [
        "#### Tweeter tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkmenV4ixNB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b834495-0eba-423d-c2f6-f0f80ed03542"
      },
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tweets = ['This is the best #nlp exercise ive found online! #python',\n",
        " '#NLP is super fun! <3 #learning',\n",
        " 'Thanks @datacamp :) #nlp #python']\n",
        "\n",
        "# Define a regex pattern to find hashtags: pattern1\n",
        "pattern1 = r\"#\\w+\"\n",
        "# Use the pattern on the first tweet in the tweets list\n",
        "hashtags = regexp_tokenize(tweets[0], pattern1)\n",
        "print(hashtags)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#nlp', '#python']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMVSuIHpx63D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddd6cd6-908f-4b6f-b6f8-cd9f717b7152"
      },
      "source": [
        "pattern2 = r'#\\w+|@\\w+'\n",
        "\n",
        "# is better to write it like this:\n",
        "\n",
        "pattern2 = r\"([@#]\\w+)\"\n",
        "# Use the pattern on the last tweet in the tweets list\n",
        "mentions_hashtags = regexp_tokenize(tweets[-1], pattern2)\n",
        "print(mentions_hashtags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@datacamp', '#nlp', '#python']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhS_icjgzJKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6b44c0-0857-4e60-92f4-f102b52c7491"
      },
      "source": [
        "# Import the necessary modules\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "# Use the TweetTokenizer to tokenize all tweets into one list\n",
        "tknzr = TweetTokenizer()\n",
        "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
        "print(all_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg2-gxj21hM7"
      },
      "source": [
        "### German Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf2UItdC1ijr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d989dd8e-f801-4139-e843-7db0badf1692"
      },
      "source": [
        "german_text = 'Wann gehen wir Pizza essen? ðŸ• Und fÃ¤hrst du mit Ãœber? ðŸš•'\n",
        "\n",
        "# Tokenize and print all words in german_text\n",
        "all_words = word_tokenize(german_text)\n",
        "print(all_words)\n",
        "\n",
        "# Tokenize and print only capital words\n",
        "capital_words = r\"[A-ZÃœ]\\w+\"\n",
        "print(regexp_tokenize(german_text, capital_words))\n",
        "\n",
        "# Tokenize and print only emoji\n",
        "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
        "print(regexp_tokenize(german_text, emoji))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Wann', 'gehen', 'wir', 'Pizza', 'essen', '?', 'ðŸ•', 'Und', 'fÃ¤hrst', 'du', 'mit', 'Ãœber', '?', 'ðŸš•']\n",
            "['Wann', 'Pizza', 'Und', 'Ãœber']\n",
            "['ðŸ•', 'ðŸš•']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWaUOtIs2Hc4"
      },
      "source": [
        "# Charting word length with NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXZvoQA62Kf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "80e46200-dc0e-4602-b57e-58410bd61c39"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "words = word_tokenize('This is a pretty cool tool!')\n",
        "\n",
        "print(words)\n",
        "\n",
        "# I want length of words\n",
        "\n",
        "word_lengths = [len(word) for word in words]\n",
        "\n",
        "plt.hist(word_lengths)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'a', 'pretty', 'cool', 'tool', '!']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIoWKzQc4yZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bc7d5103-6b1c-4129-d39a-9d58f39ad9da"
      },
      "source": [
        "\n",
        "# Split the script into lines: lines\n",
        "lines = scene_one.split('\\n')\n",
        "\n",
        "# Replace all script lines for speaker\n",
        "pattern = \"[A-Z]{2,}(\\s)?(#\\d)?([A-Z]{2,})?:\"\n",
        "lines = [re.sub(pattern, '', l) for l in lines]\n",
        "\n",
        "# Tokenize each line: tokenized_lines\n",
        "tokenized_lines = [regexp_tokenize(s, \"\\w+\") for s in lines]\n",
        "\n",
        "# Make a frequency list of lengths: line_num_words\n",
        "line_num_words = [len(t_line) for t_line in tokenized_lines]\n",
        "\n",
        "# Plot a histogram of the line lengths\n",
        "plt.hist(line_num_words)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euD8HmlM6jQ0"
      },
      "source": [
        "# Word counts with bag-of-words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poqVr8rm6nsS"
      },
      "source": [
        "Very simple and basic method for finding topics in a text\n",
        "\n",
        "For bag-of-words you'll first need to create tokens using tokenization\n",
        "\n",
        "Then count up all the tokens that you have. The more frequent the token is, the more central is for the text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1V6TIuC9AQ4"
      },
      "source": [
        "## With no lowering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lid-G2jM6mJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d721ae77-f369-4ad4-b0ab-3965959e24e2"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "text = scene_one\n",
        "\n",
        "counter = Counter(word_tokenize(text))\n",
        "\n",
        "counter.most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(':', 40), ('SOLDIER', 24), ('#', 24), (',', 23), ('1', 19)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdNGRQQJ9DW4"
      },
      "source": [
        "## lowering all words before counting for bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sImxV7jR8X4n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e015c9c3-0973-439b-ad8f-429faa386ce2"
      },
      "source": [
        "# We have to lower all words before counting for bag-of-words\n",
        "\n",
        "# Import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Tokenize the article: tokens\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Convert the tokens into lowercase: lower_tokens\n",
        "lower_tokens = [token.lower() for token in tokens]\n",
        "\n",
        "# Create a Counter with the lowercase tokens: bow_simple\n",
        "bow_simple = Counter(lower_tokens)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow_simple.most_common(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(':', 40), ('soldier', 24), ('#', 24), (',', 23), ('1', 19), ('?', 19), ('.', 18), ('arthur', 17), ('!', 17), ('the', 17)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fR-tYPvUTo"
      },
      "source": [
        "# Best tokenization lower, alphabetic, lemmatized with stop words.\n",
        "\n",
        "Text preprocessing \n",
        "\n",
        "Like tokenization and lowering cases.\n",
        "\n",
        "Others like lemmatization/Stemming.\n",
        "\n",
        "Thechniques like removing stop words (and/the, others), punctuation or unwanted tokens. Also plural words made singular."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9I8f4StyWS4"
      },
      "source": [
        "You'll need to remove stop words and non-alphabetic characters, lemmatize, and perform a new bag-of-words on your cleaned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t07K-ATFzf_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b143ae48-dddd-4f95-f59a-c76490b60591"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrt6UqMnv9p1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4f9a0970-d573-44a1-9b9a-a72de45769db"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "text = 'If you have a cat, thereâ€™s a good chance your camera roll is already full of photos of your furry feline. But that doesnâ€™t mean thereâ€™s no room for a few more. And just like cat photos, thereâ€™s also always room for a cat quote or two. '\n",
        "\n",
        "# .isalpha to only return alphabetic strings (strip tokens with numbers or punctuations)\n",
        "alpha_tokens =  [word for word in word_tokenize(text.lower()) if word.isalpha()]\n",
        "\n",
        "no_stops_tokens = [token for token in alpha_tokens if token not in stopwords.words('english')]\n",
        "\n",
        "# Instantiate the WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize all tokens into a new list: lemmatized\n",
        "lemmatized_tokens = [wordnet_lemmatizer.lemmatize(token) for token in no_stops_tokens]\n",
        "\n",
        "# Create the bag-of-words: bow\n",
        "bow = Counter(lemmatized_tokens)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow.most_common(10))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('cat', 3), ('photo', 2), ('room', 2), ('good', 1), ('chance', 1), ('camera', 1), ('roll', 1), ('already', 1), ('full', 1), ('furry', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5iN539B0Jdt"
      },
      "source": [
        "# Introduction to gensim\n",
        "\n",
        "gensim is a popular open-source NLP library\n",
        "\n",
        "Uses top academic models to perform complex tasks like: Building documents or word vectors, performing topic identification and document comparison.\n",
        "\n",
        "Word vectors are multi-dimensional mathematical representations of words created using deep learning methods. They give us insight into relationships between words in a corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LKrXYS63zI_"
      },
      "source": [
        "## Creating and querying a corpus with gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cecPtUNb0-JA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "d50de08f-dabe-4d74-fcd2-9d1c579a1957"
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# .isalpha to only return alphabetic strings (strip tokens with numbers or punctuations)\n",
        "alpha_tokens =  [word for word in word_tokenize(articles.lower()) if word.isalpha()]\n",
        "\n",
        "no_stops_tokens = [token for token in alpha_tokens if token not in stopwords.words('english')]\n",
        "\n",
        "# Instantiate the WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize all tokens into a new list: lemmatized\n",
        "# Be carefull we need 2 dimension array for Dictionary to work.\n",
        "lemmatized_tokens = [wordnet_lemmatizer.lemmatize(token) for token in no_stops_tokens]\n",
        "\n",
        "# Import Dictionary\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "# Create a Dictionary from the articles: dictionary\n",
        "dictionary = Dictionary(articles)\n",
        "\n",
        "# Select the id for \"computer\": computer_id\n",
        "computer_id = dictionary.token2id.get(\"computer\")\n",
        "\n",
        "# Use computer_id with the dictionary to print the word\n",
        "print(dictionary.get(computer_id))\n",
        "\n",
        "# Create a MmCorpus: corpus\n",
        "corpus = [dictionary.doc2bow(article) for article in articles]\n",
        "\n",
        "# Print the first 10 word ids with their frequency counts from the fifth document\n",
        "print(corpus[4][:10])\n",
        "\n",
        "# Save the fifth document: doc\n",
        "doc = corpus[4]\n",
        "\n",
        "# Sort the doc for frequency: bow_doc\n",
        "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 words of the document alongside the count\n",
        "for word_id, word_count in bow_doc[:5]:\n",
        "    print(dictionary.get(word_id), word_count)\n",
        "    \n",
        "# Create the defaultdict: total_word_count\n",
        "total_word_count = defaultdict(int)\n",
        "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
        "    total_word_count[word_id] += word_count\n",
        "\n",
        "    # Create a sorted list from the defaultdict: sorted_word_count \n",
        "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True) \n",
        "\n",
        "# Print the top 5 words across all documents alongside the count\n",
        "for word_id, word_count in sorted_word_count[:5]:\n",
        "    print(dictionary.get(word_id), word_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-89db71f77fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create a Dictionary from the articles: dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Use .token2id.get() on dictionary with \"computer\" as the argument to obtain its id.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc2bow expects an array of unicode tokens on input, not a single string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y_15OwO6_o2"
      },
      "source": [
        "Now, you'll use your new gensim corpus and dictionary to see the most common terms per document and across all documents. You can use your dictionary to look up the terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ1sfM2S7EaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "da6a2f0b-90a5-43ec-edfa-eea06f30dddc"
      },
      "source": [
        "from collections import defaultdict \n",
        "import itertools \n",
        "\n",
        "# Save the first document: doc\n",
        "doc = corpus[0]\n",
        "\n",
        "# Sort the doc for frequency: bow_doc\n",
        "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 words of the document alongside the count\n",
        "for word_id, word_count in bow_doc[:5]:\n",
        "    print(dictionary.get(word_id), word_count)\n",
        "    \n",
        "# Create the defaultdict: total_word_count\n",
        "total_word_count = defaultdict(int)\n",
        "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
        "    total_word_count[word_id] += word_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tax 3\n",
            "arrival 2\n",
            "british 2\n",
            "colony 2\n",
            "formed 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxSPOeEb9Jwr"
      },
      "source": [
        "# TF-IDF with gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRSFhIhz9rNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72dcd958-4910-4f1f-8800-c57a6f019858"
      },
      "source": [
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "# Create a new TfidfModel using the corpus: tfidf\n",
        "tfidf = TfidfModel(corpus)\n",
        "\n",
        "# Calculate the tfidf weights of doc: tfidf_weights\n",
        "tfidf_weights = tfidf[doc]\n",
        "\n",
        "# Print the first five weights\n",
        "print(tfidf_weights[:5])\n",
        "\n",
        "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
        "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 weighted words\n",
        "for term_id, weight in sorted_tfidf_weights[:5]:\n",
        "    print(dictionary.get(term_id), weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0JAff_YP19w"
      },
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "NLP task to identify important named entities in the text\n",
        "\n",
        "Such as people, places and organizations. They can even be Dates, states, works of art and other categories.\n",
        "\n",
        "Can be used alonside topic identification or on its own.\n",
        "\n",
        "NLTK has its own library and also with stanford CoreNLP library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRbawYCBWx_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "aa4d1d92-3dec-4e2b-bff8-8543e517b93e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7w1rHu4jcbU"
      },
      "source": [
        "## NER binary nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tah6MqUSRiCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7efe20d8-53ea-478d-8ee0-3413e4b1c0c8"
      },
      "source": [
        "import nltk\n",
        "article = '\\ufeffThe taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character. If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, and those who donâ€™t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, this use of it was not something the users had bargained for. Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Appleâ€™s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this â€œgreyballâ€ software against law enforcement â€“ one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uberâ€™s rides too much to care about the lack of driversâ€™ rights or pay. Many of the users themselves are not much richer than the drivers. The â€œsharing economyâ€ encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valleyâ€™s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet thereâ€™s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.'\n",
        "\n",
        "# Tokenize the article into sentences: sentences\n",
        "sentences = nltk.sent_tokenize(article)\n",
        "\n",
        "# Tokenize each sentence into words: token_sentences\n",
        "token_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "# Tag each tokenized sentence into parts of speech: pos_sentences\n",
        "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences] \n",
        "\n",
        "# Create the named entity chunks: chunked_sentences\n",
        "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=True)\n",
        "\n",
        "# Test for stems of the tree with 'NE' tags\n",
        "for sent in chunked_sentences:\n",
        "    for chunk in sent:\n",
        "        if hasattr(chunk, \"label\") and chunk.label() == \"NE\":\n",
        "            print(chunk.label())\n",
        "            print(chunk)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NE\n",
            "(NE Uber/NNP)\n",
            "NE\n",
            "(NE Beyond/NN)\n",
            "NE\n",
            "(NE Apple/NNP)\n",
            "NE\n",
            "(NE Uber/NNP)\n",
            "NE\n",
            "(NE Uber/NNP)\n",
            "NE\n",
            "(NE Travis/NNP Kalanick/NNP)\n",
            "NE\n",
            "(NE Tim/NNP Cook/NNP)\n",
            "NE\n",
            "(NE Apple/NNP)\n",
            "NE\n",
            "(NE Silicon/NNP Valley/NNP)\n",
            "NE\n",
            "(NE CEO/NNP)\n",
            "NE\n",
            "(NE Yahoo/NNP)\n",
            "NE\n",
            "(NE Marissa/NNP Mayer/NNP)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE9cAX-ijerv"
      },
      "source": [
        "## NER nltk non binary with pie chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzMOpF35fBjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "8913aee0-d645-4c84-bea2-e7ec3483f701"
      },
      "source": [
        "%matplotlib inline\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "article = '\\ufeffThe taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character. If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, and those who donâ€™t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, this use of it was not something the users had bargained for. Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Appleâ€™s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this â€œgreyballâ€ software against law enforcement â€“ one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uberâ€™s rides too much to care about the lack of driversâ€™ rights or pay. Many of the users themselves are not much richer than the drivers. The â€œsharing economyâ€ encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valleyâ€™s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet thereâ€™s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.'\n",
        "\n",
        "# Tokenize the article into sentences: sentences\n",
        "sentences = nltk.sent_tokenize(article)\n",
        "\n",
        "# Tokenize each sentence into words: token_sentences\n",
        "token_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "# Tag each tokenized sentence into parts of speech: pos_sentences\n",
        "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences] \n",
        "\n",
        "# Create the named entity chunks: chunked_sentences\n",
        "chunked_sentences = nltk.ne_chunk_sents(pos_sentences)\n",
        "\n",
        "# Create the defaultdict: ner_categories\n",
        "ner_categories = defaultdict(int)\n",
        "\n",
        "# Create the nested for loop\n",
        "for sent in chunked_sentences:\n",
        "    for chunk in sent:\n",
        "        if hasattr(chunk, 'label'):\n",
        "            print(chunk.label())\n",
        "            ner_categories[chunk.label()] += 1\n",
        "            \n",
        "# Create a list from the dictionary keys for the chart labels: labels\n",
        "labels = list(ner_categories.keys())\n",
        "\n",
        "# Create a list of the values: values\n",
        "values = [ner_categories.get(v) for v in labels]\n",
        "\n",
        "# Create the pie chart\n",
        "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPE\n",
            "PERSON\n",
            "PERSON\n",
            "PERSON\n",
            "PERSON\n",
            "PERSON\n",
            "PERSON\n",
            "ORGANIZATION\n",
            "GPE\n",
            "PERSON\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3pocwAhjqnn"
      },
      "source": [
        "# SpaCy NER \n",
        "\n",
        "NLP library similar to gensim but with different implementations\n",
        "\n",
        "Focus on creating NLP pipelines to generate models and corpora\n",
        "\n",
        "SpaCy is open source.\n",
        "\n",
        "SpaCy comes with **informal language corpora** for use in tweets, chat messages and others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOM8BcbRmw13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e3019d5-8eba-4472-9794-cb4053a22934"
      },
      "source": [
        "# We are going to use the same articles as NER\n",
        "\n",
        "article = '\\ufeffThe taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to have a moral character. If any human being were to behave with the single-minded and ruthless greed of the company, we would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, and those who donâ€™t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, to buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, this use of it was not something the users had bargained for. Beyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, attempting this with Appleâ€™s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this â€œgreyballâ€ software against law enforcement â€“ one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uberâ€™s rides too much to care about the lack of driversâ€™ rights or pay. Many of the users themselves are not much richer than the drivers. The â€œsharing economyâ€ encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valleyâ€™s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet thereâ€™s an urgent political task to tame these companies, to ensure they are punished when they break the law, that they pay their taxes fairly and that they behave responsibly.'\n",
        "\n",
        "# Import spacy\n",
        "import spacy\n",
        "\n",
        "# Instantiate the English model: nlp\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# Create a new document: doc\n",
        "doc = nlp(article)\n",
        "\n",
        "# Print all of the found entities and their labels\n",
        "for ent in doc.ents:\n",
        "    print(ent.label_, ent.text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORG Uber\n",
            "PERSON Uber\n",
            "ORG unroll.me\n",
            "ORG Apple\n",
            "PERSON Travis Kalanick\n",
            "PERSON Uber\n",
            "PERSON Tim Cook\n",
            "ORG Apple\n",
            "CARDINAL Millions\n",
            "PERSON Uber\n",
            "LOC Silicon Valley\n",
            "ORG Yahoo\n",
            "PERSON Marissa Mayer\n",
            "MONEY $186m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m82RtcZ9qTxz"
      },
      "source": [
        "# Multilingual NER polyglot\n",
        "\n",
        "Another NLP library which uses word vectors\n",
        "\n",
        "Wide variety of languages it supports.\n",
        "\n",
        "You cna use it for translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7GVtNw8tE1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3f07fc30-3f02-4e6e-b567-ca93aabff852"
      },
      "source": [
        "pip install polyglot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–‹                             | 10kB 10.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 61kB 2.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 92kB 2.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 102kB 2.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 112kB 2.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 122kB 2.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 2.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52559 sha256=a7e3e0c68f0d3d16c0a30b8dc4a25bf6d69b969ae8685485f3178715476d89cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6_YBQ2tQfy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ebd128d5-c81f-419b-c7c5-b5ba3ef2da44"
      },
      "source": [
        "pip install pycld2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41.4MB 98kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833447 sha256=980add3521e59f85459430cb171bef860783ca5c8ec4f6c62d8579f7731e1338\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWrq9ZgLtfvH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bc514f52-719d-4ffc-f320-839f55c791ba"
      },
      "source": [
        "pip install 'morfessor'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYngS2htlmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54681e18-4621-4137-b511-fd3ebc640f96"
      },
      "source": [
        "!polyglot download embeddings2.fr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package embeddings2.fr to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IsdKO2nt4ye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1375793-1de8-4553-e451-07476d13a26a"
      },
      "source": [
        "!polyglot download ner2.fr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package ner2.fr to /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jisZVYhgqygq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "58951526-f56d-4398-d560-774cd9c13202"
      },
      "source": [
        "import polyglot\n",
        "from polyglot.text import Text\n",
        "\n",
        "article = \"\\ufeffÃ©dition abonnÃ©\\r\\n\\r\\n\\r\\nDans une tribune au Â« Monde Â», lâ€™universitaire Charles Cuvelliez estime que le fantasme dâ€™un remplacement de lâ€™homme par lâ€™algorithme et le robot repose sur un malentendu.\\r\\n\\r\\n\\r\\nLe Monde | 10.05.2017 Ã  06h44 â€¢ Mis Ã  jour le 10.05.2017 Ã  09h47 | Par Charles Cuvelliez (Professeur Ã  lâ€™Ecole polytechnique de l'universitÃ© libre de Bruxelles)\\r\\n\\r\\n\\r\\nTRIBUNE. Lâ€™usage morbide, par certains, de Facebook Live a amenÃ© son fondateur Ã  annoncer prÃ©cipitamment le recrutement de 3 000 modÃ©rateurs supplÃ©mentaires. Il est vrai que lâ€™intelligence artificielle (IA) est bien en peine de reconnaÃ®tre des contenus violents, surtout diffusÃ©s en direct.\\r\\n\\r\\n\\r\\nLe quotidien affreux de ces modÃ©rateurs, contraints de visionner des horreurs Ã  longueur de journÃ©e, mÃ©riterait pourtant quâ€™on les remplace vite par des machines !\\r\\n\\r\\n\\r\\nLâ€™IA ne peut pas tout, mais lÃ  oÃ¹ elle peut beaucoup, on la maudit, accusÃ©e de dÃ©truire nos emplois, de remplacer la convivialitÃ© humaine. Ce dÃ©bat repose sur un malentendu.\\r\\n\\r\\n\\r\\nIl vient dâ€™une dÃ©finition de lâ€™IA qui nâ€™a, dans la rÃ©alitÃ©, jamais pu Ãªtre mise en pratique : en 1955, elle Ã©tait vue comme la crÃ©ation de programmes informatiques qui, quoi quâ€™on leur confie, le feraient un jour mieux que les humains. On pensait que toute caractÃ©ristique de lâ€™intelligence humaine pourrait un jour Ãªtre si prÃ©cisÃ©ment dÃ©crite quâ€™il suffirait dâ€™une machine pour la simuler. Ce nâ€™est pas vrai.\\r\\n\\r\\n\\r\\nAngoisses infondÃ©es\\r\\n\\r\\n\\r\\nComme le dit un rÃ©cent Livre blanc sur la question (Pourquoi il ne faut pas avoir peur de lâ€™Intelligence arti\\xadficielle, Julien Maldonato, Deloitte, mars 2017), rien ne pourra remplacer un humain dans sa globalitÃ©.\\r\\n\\r\\n\\r\\nLâ€™IA, câ€™est de lâ€™apprentissage automatique dotÃ© dâ€™un processus dâ€™ajustement de modÃ¨les statistiques Ã  des masses de donnÃ©es, explique lâ€™auteur. Il sâ€™agit dâ€™un apprentissage sur des paramÃ¨tres pour lesquels une vision humaine nâ€™explique pas pourquoi ils marchent si bien dans un contexte donnÃ©.\\r\\n\\r\\n\\r\\nCâ€™est aussi ce que dit le rapport de lâ€™Office parlementaire dâ€™Ã©valuation des choix scientifiques et technologiques (Â« Pour une intelligence artificielle maÃ®trisÃ©e, utile et dÃ©mystifiÃ©e Â», 29 mars 2017), pour qui ce cÃ´tÃ© Â« boÃ®te noire Â» explique des angoisses infondÃ©es. Ethiquement, se fonder sur lâ€™IA pour des tÃ¢ches critiques sans bien comprendre le comment...\"\n",
        "# Create a new text object using Polyglot's Text class: txt\n",
        "txt = Text(article)\n",
        "\n",
        "# Print each of the entities found\n",
        "for ent in txt.entities:\n",
        "    print(ent)\n",
        "    \n",
        "# Print the type of ent\n",
        "print(type(ent))\n",
        "\n",
        "# Create the list of tuples: entities\n",
        "entities = [(ent.tag, ' '.join(ent)) for ent in txt.entities]\n",
        "\n",
        "# Print entities\n",
        "print(entities)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Charles', 'Cuvelliez']\n",
            "['Charles', 'Cuvelliez']\n",
            "['Bruxelles']\n",
            "['lâ€™IA']\n",
            "['Julien', 'Maldonato']\n",
            "['Deloitte']\n",
            "['Ethiquement']\n",
            "['lâ€™IA']\n",
            "['.']\n",
            "<class 'polyglot.text.Chunk'>\n",
            "[('I-PER', 'Charles Cuvelliez'), ('I-PER', 'Charles Cuvelliez'), ('I-ORG', 'Bruxelles'), ('I-PER', 'lâ€™IA'), ('I-PER', 'Julien Maldonato'), ('I-ORG', 'Deloitte'), ('I-PER', 'Ethiquement'), ('I-LOC', 'lâ€™IA'), ('I-PER', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83AxDK1Zuo1f"
      },
      "source": [
        "# Classifying fake news with sklearn CountVectorizer\n",
        "\n",
        "How to create a supervised model from text: By using bag-of-words or tf-idf as features. Extract features from the text to help predict the labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTpn0xlTWCSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8dd4c14c-70c8-455a-d914-15c513fa79a1"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "df = pd.read_csv('https://s3.amazonaws.com/assets.datacamp.com/production/course_3629/fake_or_real_news.csv')\n",
        "display(df.head())\n",
        "\n",
        "y = df.label\n",
        "y = y.apply(lambda row: 0 if row == 'REAL' else 1)\n",
        "X = df.text\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillaryâ€™s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>â€” Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... label\n",
              "0        8476  ...  FAKE\n",
              "1       10294  ...  FAKE\n",
              "2        3608  ...  REAL\n",
              "3       10142  ...  FAKE\n",
              "4         875  ...  REAL\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    0\n",
              "3    1\n",
              "4    0\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dXlDGx4depe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0690f1f4-bc2b-4b8d-94b0-238814f1086c"
      },
      "source": [
        "y = df.label\n",
        "y = y.apply(lambda row: 0 if row == 'REAL' else 1)\n",
        "X = df.text\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       0\n",
              "3       1\n",
              "4       0\n",
              "       ..\n",
              "6330    0\n",
              "6331    1\n",
              "6332    1\n",
              "6333    0\n",
              "6334    0\n",
              "Name: label, Length: 6335, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMdJscYplTL6"
      },
      "source": [
        "## Classifier with Naive Bayes and CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wTco-GoSq-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "698be8e9-c6bc-429e-c0ed-71019ecc8953"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Create training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)\n",
        "\n",
        "# Initialize a CountVectorizer object: count_vectorizer\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Transform the training data using only the 'text' column values: count_train \n",
        "count_train = count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using only the 'text' column values: count_test \n",
        "count_test = count_vectorizer.transform(X_test)\n",
        "\n",
        "# Print the first 10 features of the count_vectorizer\n",
        "print(count_vectorizer.get_feature_names()[:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i5ERw7ZYOED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "14731c52-2d18-45b7-deb2-5eb96b55c8da"
      },
      "source": [
        "# Create the CountVectorizer DataFrame: count_df\n",
        "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
        "count_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000031</th>\n",
              "      <th>000035</th>\n",
              "      <th>00006</th>\n",
              "      <th>0001</th>\n",
              "      <th>0001pt</th>\n",
              "      <th>000ft</th>\n",
              "      <th>000km</th>\n",
              "      <th>001</th>\n",
              "      <th>0011</th>\n",
              "      <th>002</th>\n",
              "      <th>003</th>\n",
              "      <th>004</th>\n",
              "      <th>006</th>\n",
              "      <th>006s</th>\n",
              "      <th>007</th>\n",
              "      <th>007s</th>\n",
              "      <th>008</th>\n",
              "      <th>008s</th>\n",
              "      <th>009</th>\n",
              "      <th>0099</th>\n",
              "      <th>00am</th>\n",
              "      <th>00p</th>\n",
              "      <th>00pm</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>013</th>\n",
              "      <th>014</th>\n",
              "      <th>015</th>\n",
              "      <th>016</th>\n",
              "      <th>018</th>\n",
              "      <th>01am</th>\n",
              "      <th>02</th>\n",
              "      <th>020</th>\n",
              "      <th>022</th>\n",
              "      <th>023</th>\n",
              "      <th>024</th>\n",
              "      <th>025</th>\n",
              "      <th>...</th>\n",
              "      <th>×©×•×œ×˜×™×</th>\n",
              "      <th>×©×–×•</th>\n",
              "      <th>×©×˜×—×™×</th>\n",
              "      <th>×©×™× ×•×™</th>\n",
              "      <th>×©×™×ª×¢×§×©</th>\n",
              "      <th>×©×›×œ</th>\n",
              "      <th>×©×›×ž×•× ×™</th>\n",
              "      <th>×©×œ</th>\n",
              "      <th>×©×œ×•</th>\n",
              "      <th>×©× ×“×¨×©</th>\n",
              "      <th>×©× ×™</th>\n",
              "      <th>×©×¢×ª</th>\n",
              "      <th>×©×ª×™</th>\n",
              "      <th>×ª××ž×¦× ×”</th>\n",
              "      <th>×ª×•×¦××”</th>\n",
              "      <th>×ª×—×œ</th>\n",
              "      <th>×ª×™×™×¨×•×ª</th>\n",
              "      <th>×ª× ×•×ª×§</th>\n",
              "      <th>×ª×¢×•×“×ª</th>\n",
              "      <th>×ª×ª×¨×›×–</th>\n",
              "      <th>Ø£Ù†</th>\n",
              "      <th>Ø¥Ø¬Ù„Ø§Ø¡</th>\n",
              "      <th>Ø§Ù„Ø£Ù…Ø±</th>\n",
              "      <th>Ø§Ù„Ø¬Ø±Ø­Ù‰</th>\n",
              "      <th>Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©</th>\n",
              "      <th>Ø§Ù„Ù‚Ø§Ø¯Ù…ÙˆÙ†</th>\n",
              "      <th>Ø§Ù„Ù„Ø¬Ù†Ø©</th>\n",
              "      <th>ØªØ­ØªØ§Ø¬</th>\n",
              "      <th>ØªØ¹Ø±ÙÙ‡</th>\n",
              "      <th>ØªÙ†Ø¬Ø­</th>\n",
              "      <th>Ø­Ù„Ø¨</th>\n",
              "      <th>Ø¹Ø±Ø¨ÙŠ</th>\n",
              "      <th>Ø¹Ù†</th>\n",
              "      <th>Ù„Ù…</th>\n",
              "      <th>Ù…Ø§</th>\n",
              "      <th>Ù…Ø­Ø§ÙˆÙ„Ø§Øª</th>\n",
              "      <th>Ù…Ù†</th>\n",
              "      <th>Ù‡Ø°Ø§</th>\n",
              "      <th>ÙˆØ§Ù„Ù…Ø±Ø¶Ù‰</th>\n",
              "      <th>à¸¢à¸‡ade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4240</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4241</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4242</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4243</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4244 rows Ã— 56922 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      00  000  0000  00000031  000035  ...  Ù…Ø­Ø§ÙˆÙ„Ø§Øª  Ù…Ù†  Ù‡Ø°Ø§  ÙˆØ§Ù„Ù…Ø±Ø¶Ù‰  à¸¢à¸‡ade\n",
              "0      0    0     0         0       0  ...        0   0    0        0      0\n",
              "1      0    0     0         0       0  ...        0   0    0        0      0\n",
              "2      0    0     0         0       0  ...        0   0    0        0      0\n",
              "3      0    0     0         0       0  ...        0   0    0        0      0\n",
              "4      0    0     0         0       0  ...        0   0    0        0      0\n",
              "...   ..  ...   ...       ...     ...  ...      ...  ..  ...      ...    ...\n",
              "4239   0    1     0         0       0  ...        0   0    0        0      0\n",
              "4240   0    0     0         0       0  ...        0   0    0        0      0\n",
              "4241   0    0     0         0       0  ...        0   0    0        0      0\n",
              "4242   0    0     0         0       0  ...        0   0    0        0      0\n",
              "4243   0    0     0         0       0  ...        0   0    0        0      0\n",
              "\n",
              "[4244 rows x 56922 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCKx3tZWZvTE"
      },
      "source": [
        "Commonly used for testing NLP classification problems\n",
        "Basis in probability\n",
        "\n",
        "Each word from CountVectorizer acts as a feature. Simple and effective.\n",
        "\n",
        "Doesn't work with sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHCgKPy7aRVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e2b42aa-8432-498b-c872-80783632fca0"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "nb_classifier.fit(count_train, y_train)\n",
        "pred = nb_classifier.predict(count_test)\n",
        "\n",
        "metrics.accuracy_score(y_test,pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.893352462936394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8EmmTeIbToR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b27fb215-3c68-4c17-8a81-075212a5a548"
      },
      "source": [
        "# Let's print confusion matrix\n",
        "\n",
        "metrics.confusion_matrix(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1003,   80],\n",
              "       [ 143,  865]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0_K4IGRb-L9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3ebfae24-ad10-4496-aa60-7ee738af8f03"
      },
      "source": [
        "print(metrics.precision_score(y_test, pred))\n",
        "print(metrics.recall_score(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9153439153439153\n",
            "0.8581349206349206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bmPpw5mfTF1"
      },
      "source": [
        "## Classifier with Naive Bayes and TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVDP0llJXX1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b4dbe9dd-4321-47bd-bdd4-ceb0e8b7d65b"
      },
      "source": [
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "# Transform the training data: tfidf_train \n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data: tfidf_test \n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Print the first 10 features\n",
        "print(tfidf_vectorizer.get_feature_names()[:10])\n",
        "\n",
        "# Print the first 5 vectors of the tfidf training data\n",
        "print(tfidf_train.A[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxL4-3JvYmue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "ea41e3c1-7267-429c-9171-11b2eabc15a6"
      },
      "source": [
        "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
        "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
        "tfidf_df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000031</th>\n",
              "      <th>000035</th>\n",
              "      <th>00006</th>\n",
              "      <th>0001</th>\n",
              "      <th>0001pt</th>\n",
              "      <th>000ft</th>\n",
              "      <th>000km</th>\n",
              "      <th>001</th>\n",
              "      <th>0011</th>\n",
              "      <th>002</th>\n",
              "      <th>003</th>\n",
              "      <th>004</th>\n",
              "      <th>006</th>\n",
              "      <th>006s</th>\n",
              "      <th>007</th>\n",
              "      <th>007s</th>\n",
              "      <th>008</th>\n",
              "      <th>008s</th>\n",
              "      <th>009</th>\n",
              "      <th>0099</th>\n",
              "      <th>00am</th>\n",
              "      <th>00p</th>\n",
              "      <th>00pm</th>\n",
              "      <th>01</th>\n",
              "      <th>010</th>\n",
              "      <th>013</th>\n",
              "      <th>014</th>\n",
              "      <th>015</th>\n",
              "      <th>016</th>\n",
              "      <th>018</th>\n",
              "      <th>01am</th>\n",
              "      <th>02</th>\n",
              "      <th>020</th>\n",
              "      <th>022</th>\n",
              "      <th>023</th>\n",
              "      <th>024</th>\n",
              "      <th>025</th>\n",
              "      <th>...</th>\n",
              "      <th>×©×•×œ×˜×™×</th>\n",
              "      <th>×©×–×•</th>\n",
              "      <th>×©×˜×—×™×</th>\n",
              "      <th>×©×™× ×•×™</th>\n",
              "      <th>×©×™×ª×¢×§×©</th>\n",
              "      <th>×©×›×œ</th>\n",
              "      <th>×©×›×ž×•× ×™</th>\n",
              "      <th>×©×œ</th>\n",
              "      <th>×©×œ×•</th>\n",
              "      <th>×©× ×“×¨×©</th>\n",
              "      <th>×©× ×™</th>\n",
              "      <th>×©×¢×ª</th>\n",
              "      <th>×©×ª×™</th>\n",
              "      <th>×ª××ž×¦× ×”</th>\n",
              "      <th>×ª×•×¦××”</th>\n",
              "      <th>×ª×—×œ</th>\n",
              "      <th>×ª×™×™×¨×•×ª</th>\n",
              "      <th>×ª× ×•×ª×§</th>\n",
              "      <th>×ª×¢×•×“×ª</th>\n",
              "      <th>×ª×ª×¨×›×–</th>\n",
              "      <th>Ø£Ù†</th>\n",
              "      <th>Ø¥Ø¬Ù„Ø§Ø¡</th>\n",
              "      <th>Ø§Ù„Ø£Ù…Ø±</th>\n",
              "      <th>Ø§Ù„Ø¬Ø±Ø­Ù‰</th>\n",
              "      <th>Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©</th>\n",
              "      <th>Ø§Ù„Ù‚Ø§Ø¯Ù…ÙˆÙ†</th>\n",
              "      <th>Ø§Ù„Ù„Ø¬Ù†Ø©</th>\n",
              "      <th>ØªØ­ØªØ§Ø¬</th>\n",
              "      <th>ØªØ¹Ø±ÙÙ‡</th>\n",
              "      <th>ØªÙ†Ø¬Ø­</th>\n",
              "      <th>Ø­Ù„Ø¨</th>\n",
              "      <th>Ø¹Ø±Ø¨ÙŠ</th>\n",
              "      <th>Ø¹Ù†</th>\n",
              "      <th>Ù„Ù…</th>\n",
              "      <th>Ù…Ø§</th>\n",
              "      <th>Ù…Ø­Ø§ÙˆÙ„Ø§Øª</th>\n",
              "      <th>Ù…Ù†</th>\n",
              "      <th>Ù‡Ø°Ø§</th>\n",
              "      <th>ÙˆØ§Ù„Ù…Ø±Ø¶Ù‰</th>\n",
              "      <th>à¸¢à¸‡ade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4240</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4241</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4242</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4243</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4244 rows Ã— 56922 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       00       000  0000  00000031  000035  ...  Ù…Ø­Ø§ÙˆÙ„Ø§Øª   Ù…Ù†  Ù‡Ø°Ø§  ÙˆØ§Ù„Ù…Ø±Ø¶Ù‰  à¸¢à¸‡ade\n",
              "0     0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "1     0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "2     0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "3     0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "4     0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "...   ...       ...   ...       ...     ...  ...      ...  ...  ...      ...    ...\n",
              "4239  0.0  0.014123   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "4240  0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "4241  0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "4242  0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "4243  0.0  0.000000   0.0       0.0     0.0  ...      0.0  0.0  0.0      0.0    0.0\n",
              "\n",
              "[4244 rows x 56922 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE7vZg9Uld81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a3845100-3dda-4d6f-a8b9-4bdf5b033908"
      },
      "source": [
        "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "nb_classifier.fit(tfidf_train, y_train)\n",
        "\n",
        "# Create the predicted tags: pred\n",
        "pred = nb_classifier.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score: score\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "print(score)\n",
        "\n",
        "# Calculate the confusion matrix: cm\n",
        "cm = metrics.confusion_matrix(y_test, pred)\n",
        "print(cm)\n",
        "\n",
        "print(metrics.precision_score(y_test, pred))\n",
        "print(metrics.recall_score(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8565279770444764\n",
            "[[1052   31]\n",
            " [ 269  739]]\n",
            "0.9597402597402598\n",
            "0.7331349206349206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkA3DG6mkOt"
      },
      "source": [
        "## Naive Bayes has an alpha hyperparameter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poChHLzFmrfD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "32fcee24-172c-4677-d262-6ddbe051952f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the list of alphas: alphas\n",
        "alphas = np.arange(0, 1, .1)\n",
        "\n",
        "# Define train_and_predict()\n",
        "def train_and_predict(alpha):\n",
        "    # Instantiate the classifier: nb_classifier\n",
        "    nb_classifier = MultinomialNB(alpha=alpha)\n",
        "    # Fit to the training data\n",
        "    nb_classifier.fit(tfidf_train, y_train)\n",
        "    # Predict the labels: pred\n",
        "    pred = nb_classifier.predict(tfidf_test)\n",
        "    # Compute accuracy: score\n",
        "    score = metrics.accuracy_score(y_test, pred)\n",
        "    return score\n",
        "\n",
        "# Iterate over the alphas and print the corresponding score\n",
        "for alpha in alphas:\n",
        "    print('Alpha: ', alpha)\n",
        "    print('Score: ', train_and_predict(alpha))\n",
        "    print()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha:  0.0\n",
            "Score:  0.8813964610234337\n",
            "\n",
            "Alpha:  0.1\n",
            "Score:  0.8976566236250598\n",
            "\n",
            "Alpha:  0.2\n",
            "Score:  0.8938307030129125\n",
            "\n",
            "Alpha:  0.30000000000000004\n",
            "Score:  0.8900047824007652\n",
            "\n",
            "Alpha:  0.4\n",
            "Score:  0.8857006217120995\n",
            "\n",
            "Alpha:  0.5\n",
            "Score:  0.8842659014825442\n",
            "\n",
            "Alpha:  0.6000000000000001\n",
            "Score:  0.874701099952176\n",
            "\n",
            "Alpha:  0.7000000000000001\n",
            "Score:  0.8703969392635102\n",
            "\n",
            "Alpha:  0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score:  0.8660927785748446\n",
            "\n",
            "Alpha:  0.9\n",
            "Score:  0.8589191774270684\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p25Em5pnAje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eb7c5dfa-7e32-4030-afdd-25e077ef4853"
      },
      "source": [
        "# Get the class labels: class_labels\n",
        "class_labels = nb_classifier.classes_\n",
        "\n",
        "# Extract the features: feature_names\n",
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
        "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
        "\n",
        "# Print the first class label and the top 20 feat_with_weights entries\n",
        "print(class_labels[0], feat_with_weights[:20])\n",
        "\n",
        "# Print the second class label and the bottom 20 feat_with_weights entries\n",
        "print(class_labels[1], feat_with_weights[-20:])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [(-11.280753302177917, '00000031'), (-11.280753302177917, '00006'), (-11.280753302177917, '000ft'), (-11.280753302177917, '001'), (-11.280753302177917, '002'), (-11.280753302177917, '003'), (-11.280753302177917, '006'), (-11.280753302177917, '008'), (-11.280753302177917, '010'), (-11.280753302177917, '013'), (-11.280753302177917, '025'), (-11.280753302177917, '027'), (-11.280753302177917, '035'), (-11.280753302177917, '037'), (-11.280753302177917, '040'), (-11.280753302177917, '044'), (-11.280753302177917, '048'), (-11.280753302177917, '066'), (-11.280753302177917, '068'), (-11.280753302177917, '075')]\n",
            "1 [(-8.036772745824807, 'president'), (-8.022187159522364, 'american'), (-8.013319806154513, 'media'), (-8.007761560290644, 'donald'), (-8.006632122322646, 'october'), (-7.989623223030759, 'government'), (-7.929695447721539, 'like'), (-7.922750601304927, 'war'), (-7.915731838943572, 'new'), (-7.908889774759155, 'world'), (-7.885018054191407, 'just'), (-7.758145325115569, 'said'), (-7.7498037548099585, 'russia'), (-7.697669509488481, 'fbi'), (-7.604825769578616, '2016'), (-7.554879292243166, 'election'), (-7.541640806988918, 'people'), (-7.235945549755579, 'hillary'), (-6.923220068888362, 'clinton'), (-6.867377223688766, 'trump')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}